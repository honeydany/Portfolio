{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Определение токсичных комментариев"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Содержание<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Введение\" data-toc-modified-id=\"Введение-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Введение</a></span></li><li><span><a href=\"#Подготовка\" data-toc-modified-id=\"Подготовка-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Подготовка</a></span><ul class=\"toc-item\"><li><span><a href=\"#Загрузка\" data-toc-modified-id=\"Загрузка-2.1\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span>Загрузка</a></span></li><li><span><a href=\"#Предобработка\" data-toc-modified-id=\"Предобработка-2.2\"><span class=\"toc-item-num\">2.2&nbsp;&nbsp;</span>Предобработка</a></span><ul class=\"toc-item\"><li><span><a href=\"#Очистка,-приведение-к-нижнему-регистру\" data-toc-modified-id=\"Очистка,-приведение-к-нижнему-регистру-2.2.1\"><span class=\"toc-item-num\">2.2.1&nbsp;&nbsp;</span>Очистка, приведение к нижнему регистру</a></span></li><li><span><a href=\"#Лемматизация-текста\" data-toc-modified-id=\"Лемматизация-текста-2.2.2\"><span class=\"toc-item-num\">2.2.2&nbsp;&nbsp;</span>Лемматизация текста</a></span></li><li><span><a href=\"#Разбивка-на-обучающую,-тестовую-выборки,-скоринг-TF-IDF\" data-toc-modified-id=\"Разбивка-на-обучающую,-тестовую-выборки,-скоринг-TF-IDF-2.2.3\"><span class=\"toc-item-num\">2.2.3&nbsp;&nbsp;</span>Разбивка на обучающую, тестовую выборки, скоринг TF-IDF</a></span></li></ul></li></ul></li><li><span><a href=\"#Обучение-и-предсказания\" data-toc-modified-id=\"Обучение-и-предсказания-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Обучение и предсказания</a></span><ul class=\"toc-item\"><li><span><a href=\"#LogisticRegression\" data-toc-modified-id=\"LogisticRegression-3.1\"><span class=\"toc-item-num\">3.1&nbsp;&nbsp;</span>LogisticRegression</a></span></li><li><span><a href=\"#RandomForestClassifier\" data-toc-modified-id=\"RandomForestClassifier-3.2\"><span class=\"toc-item-num\">3.2&nbsp;&nbsp;</span>RandomForestClassifier</a></span></li><li><span><a href=\"#CatBoostClassifier\" data-toc-modified-id=\"CatBoostClassifier-3.3\"><span class=\"toc-item-num\">3.3&nbsp;&nbsp;</span>CatBoostClassifier</a></span></li><li><span><a href=\"#LGBMClassifier\" data-toc-modified-id=\"LGBMClassifier-3.4\"><span class=\"toc-item-num\">3.4&nbsp;&nbsp;</span>LGBMClassifier</a></span></li></ul></li><li><span><a href=\"#Итоги-исследования\" data-toc-modified-id=\"Итоги-исследования-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Итоги исследования</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Введение\n",
    "\n",
    "Интернет-магазин «Викишоп» запускает новый сервис. Теперь пользователи могут редактировать и дополнять описания товаров, как в вики-сообществах. То есть клиенты предлагают свои правки и комментируют изменения других. Магазину нужен инструмент, который будет искать токсичные комментарии и отправлять их на модерацию. \n",
    "\n",
    "Обучите модель классифицировать комментарии на позитивные и негативные. В вашем распоряжении набор данных с разметкой о токсичности правок.\n",
    "\n",
    "**Цель** - построить модель определения токсичных комментариев со значением метрики качества *F1* не меньше 0.75. \n",
    "\n",
    "**Задачи:**\n",
    "\n",
    "1. Загрузите и подготовьте данные.\n",
    "\n",
    "В рамках подготовки выполним следующее:\n",
    "* Выполняют токенизацию каждого текста, то есть его разбивают на слова;\n",
    "* Слова лемматизируют: приводят к начальной словарной форме (более сложные модели, например, BERT, этого не требуют: они сами понимают формы слов);\n",
    "* Текст очищают от стоп-слов и ненужных символов;\n",
    "* Затем предложения передают модели, которая переводит их в векторные представления. Для этого модель обращается к составленному заранее словарю токенов. На выходе для каждого текста образуются векторы заданной длины.\n",
    "\n",
    "2. Обучите разные модели. \n",
    "3. Подвести итоги исследования.\n",
    "\n",
    "Для выполнения проекта применять *BERT* необязательно, но вы можете попробовать.\n",
    "\n",
    "**Описание данных**\n",
    "\n",
    "Данные находятся в файле `toxic_comments.csv`. Столбец *text* в нём содержит текст комментария, а *toxic* — целевой признак."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Подготовка"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Загрузка"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# импорт бибилиотек и модулей\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import catboost as ctb\n",
    "import lightgbm as lgb\n",
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "import re\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 159571 entries, 0 to 159570\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count   Dtype \n",
      "---  ------  --------------   ----- \n",
      " 0   text    159571 non-null  object\n",
      " 1   toxic   159571 non-null  int64 \n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 2.4+ MB\n"
     ]
    }
   ],
   "source": [
    "# выгрузим файл, выведем основную информацию на экран\n",
    "df = pd.read_csv('toxic_comments.csv') #\n",
    "\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>toxic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>24915</th>\n",
       "      <td>YOU ARE A FAT, GEEKY PRICK WHO HAS NOTHING TO ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75819</th>\n",
       "      <td>Agent X2: Basically thanks - with a 'little' m...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53891</th>\n",
       "      <td>Why are my posts being deleted? \\n\\nI have tri...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154159</th>\n",
       "      <td>\"\\n\\n Controlled Demolitions and Common Sense ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13040</th>\n",
       "      <td>I do not understand your reply.  //Blaxthos ( ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123190</th>\n",
       "      <td>Is this the bizarro world? Removing content is...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33626</th>\n",
       "      <td>Well, WP:RS says that articles should use reli...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1150</th>\n",
       "      <td>Oh hear me go someone removes all my pages i g...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48633</th>\n",
       "      <td>can't believe this article was deleted\\nI'm su...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42817</th>\n",
       "      <td>\"\\n\\n Comments on GamerGate Workshop page \\n\\n...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     text  toxic\n",
       "24915   YOU ARE A FAT, GEEKY PRICK WHO HAS NOTHING TO ...      1\n",
       "75819   Agent X2: Basically thanks - with a 'little' m...      0\n",
       "53891   Why are my posts being deleted? \\n\\nI have tri...      0\n",
       "154159  \"\\n\\n Controlled Demolitions and Common Sense ...      0\n",
       "13040   I do not understand your reply.  //Blaxthos ( ...      0\n",
       "123190  Is this the bizarro world? Removing content is...      0\n",
       "33626   Well, WP:RS says that articles should use reli...      0\n",
       "1150    Oh hear me go someone removes all my pages i g...      0\n",
       "48633   can't believe this article was deleted\\nI'm su...      0\n",
       "42817   \"\\n\\n Comments on GamerGate Workshop page \\n\\n...      0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sample(10, random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Предобработка"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# разделим фичи и целевые признаки\n",
    "features = df['text'].values\n",
    "target = df['toxic']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Очистка, приведение к нижнему регистру"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--------------------\n",
      " До обработки \n",
      "-------------------- \n",
      " D'aww! He matches this background colour I'm seemingly stuck with. Thanks.  (talk) 21:51, January 11, 2016 (UTC)\n",
      "\n",
      "--------------------\n",
      " После обработки \n",
      "-------------------- \n",
      " d aww he matches this background colour i m seemingly stuck with thanks talk january utc\n"
     ]
    }
   ],
   "source": [
    "def clear_text(text):   \n",
    "    \"\"\"Очищает текст от ненужных символов\"\"\"\n",
    "    a = re.sub(r'[^a-zA-Z ]', ' ', text)\n",
    "    a = ' '.join(a.split())\n",
    "    return a\n",
    "\n",
    "# циклом пройдем по каждой строке вернем очищенный текст\n",
    "features_cleared = []\n",
    "n = int(features.shape[0])\n",
    "\n",
    "for i in range(n):\n",
    "    features_cleared.append( str.lower(clear_text(features[i])) )\n",
    "\n",
    "# переведем список в Series\n",
    "features_cleared = pd.Series( features_cleared ) \n",
    "\n",
    "print('\\n--------------------\\n До обработки \\n-------------------- \\n',features[1])\n",
    "print('\\n--------------------\\n После обработки \\n-------------------- \\n',features_cleared[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Лемматизация текста"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Danil\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Исходный текст: d aww he matches this background colour i m seemingly stuck with thanks talk january utc\n",
      "----------------------------------------------------\n",
      "Лемматизированный текст: d aww he match this background colour i m seemingly stuck with thanks talk january utc\n",
      "Wall time: 1min 5s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "nltk.download('wordnet') # загрузим данные из библиотеки nltk.download('wordnet') для лемматизации\n",
    "\n",
    "# присвоим объекту wnl структуру данных WordNetLemmatizer()\n",
    "wnl = WordNetLemmatizer()\n",
    "\n",
    "def lemma_func(text):\n",
    "    \n",
    "    \"\"\"Функция токенизирует и лемматизирует текст датафрейма, \n",
    "        возвращает pd.Series\"\"\"\n",
    "    \n",
    "    text_lemmatized = []\n",
    "    \n",
    "    # счетчик количества предложений\n",
    "    n = int(text.shape[0])\n",
    "    \n",
    "    # циклом пройдем по каждой строке\n",
    "    for i in range(n):\n",
    "        # разделим слова по пробелу\n",
    "        txt_splitted = text[i].split(' ')\n",
    "        \n",
    "        # пройдем по каждому слову списка 'txt_splitted', вернем его лемму, соединим в список lemmatized_output\n",
    "        lemmatized_output = ' '.join([wnl.lemmatize(w) for w in txt_splitted])\n",
    "    \n",
    "        # добавим в итоговый список полученной лемматизированное предложение\n",
    "        text_lemmatized.append(lemmatized_output)\n",
    "    \n",
    "    return pd.Series(text_lemmatized)\n",
    "\n",
    "features_lemmatized = lemma_func(features_cleared)\n",
    "\n",
    "print(\"Исходный текст:\", features_cleared[1])\n",
    "print('----------------------------------------------------')\n",
    "print(\"Лемматизированный текст:\", features_lemmatized[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Разбивка на обучающую, тестовую выборки, скоринг TF-IDF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* разбивка на обучающую, тестовую выборки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(features_lemmatized, target, test_size=0.25, random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* скоринг TF-IDF с учетом стоп-слов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Danil\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Размер TF-IDF-массива train: (119678, 133434)\n",
      "Размер TF-IDF-массива test: (39893, 133434)\n"
     ]
    }
   ],
   "source": [
    "# 1) Создадим счётчик\n",
    "# 2) Чтобы он считал словосочетания, укажем размер N-граммы через аргумент 'ngram_range'\n",
    "# 3) Чтобы почистить мешок слов, найдём стоп-слова, то есть слова без смысловой нагрузки.\n",
    "#    3.1) загрузим список стоп-слов:\n",
    "nltk.download('stopwords')\n",
    "\n",
    "#    3.2) Вызовем функцию stopwords.words(), передадим ей аргумент 'english', то есть англоязычные стоп-слова:\n",
    "stop_words = set(stopwords.words('english')) \n",
    "#    3.3) передадим список стоп-слов в счётчик TfidfVectorizer():\n",
    "tf_idf_vect = TfidfVectorizer(stop_words=stop_words)\n",
    "\n",
    "# Сначала применим TfidfVectorizer() на обучающей выборке и преобразуем в матрицу функций TF-IDF \n",
    "# Чтобы посчитать TF-IDF для корпуса текстов, вызовем функцию fit_transform на обучающей выборке:\n",
    "tf_idf_train = tf_idf_vect.fit_transform(X_train)\n",
    "\n",
    "# TF-IDF для корпуса текстов test-выбоки, вызовем функцию transform на тестовой выборке:\n",
    "tf_idf_test = tf_idf_vect.transform(X_test)\n",
    "\n",
    "print('Размер TF-IDF-массива train:', tf_idf_train.shape)\n",
    "print('Размер TF-IDF-массива test:', tf_idf_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Вывод:**\n",
    "* Произведена очистка от ненужных символов, приведение к нижнему регистру\n",
    "* Выполнена лемматизация текста\n",
    "* Данные разбиты на обучающую, тестовую выборки, произведен скоринг векторов слов методом TF-IDF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Обучение и предсказания"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Создадим словарь, в который запишем результаты вычислений метрики качества предсказаний на обучающих и тестовых данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_dict = {\n",
    "    'train_set':{'LogisticRegression':list(),\n",
    "                 'RandomForestClassifier':list(),\n",
    "                 'CatBoostClassifier':list(),\n",
    "                 'LGBMClassifier':list()\n",
    "                },\n",
    "    'test_set':{'LogisticRegression':list(),\n",
    "                 'RandomForestClassifier':list(),\n",
    "                 'CatBoostClassifier':list(),\n",
    "                 'LGBMClassifier':list()\n",
    "               }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions shape on train set -  (119678,)\n",
      "F1-score on train set -  0.7602147330748583\n",
      "Wall time: 1.73 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "model = LogisticRegression(solver='liblinear')\n",
    "\n",
    "model.fit(tf_idf_train, y_train)\n",
    "pred_train = model.predict(tf_idf_train)\n",
    "\n",
    "score_train = f1_score(pred_train, y_train)\n",
    "\n",
    "print('Predictions shape on train set - ', pred_train.shape)\n",
    "print('F1-score on train set - ', score_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions shape on test set -  (39893,)\n",
      "F1-score on test set -  0.7324859592078038\n"
     ]
    }
   ],
   "source": [
    "pred_test = model.predict(tf_idf_test)\n",
    "\n",
    "score_test = f1_score(pred_test, y_test)\n",
    "\n",
    "print('Predictions shape on test set - ', pred_test.shape)\n",
    "print('F1-score on test set - ', score_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_dict['train_set']['LogisticRegression'] = np.round(score_train, 3)\n",
    "results_dict['test_set']['LogisticRegression'] = np.round(score_test, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions shape on train set -  (119678,)\n",
      "F1-score on train set -  0.998346970824035\n",
      "Wall time: 7min 27s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "rnd_frst = RandomForestClassifier(random_state=1)\n",
    "\n",
    "rnd_frst.fit(tf_idf_train, y_train)\n",
    "pred_train = rnd_frst.predict(tf_idf_train)\n",
    "\n",
    "score_train = f1_score(pred_train, y_train)\n",
    "\n",
    "print('Predictions shape on train set - ', pred_train.shape)\n",
    "print('F1-score on train set - ', score_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions shape on test set -  (39893,)\n",
      "F1-score on test set -  0.6987364895722332\n"
     ]
    }
   ],
   "source": [
    "pred_test = rnd_frst.predict(tf_idf_test)\n",
    "\n",
    "score_test = f1_score(pred_test, y_test)\n",
    "\n",
    "print('Predictions shape on test set - ', pred_test.shape)\n",
    "print('F1-score on test set - ', score_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_dict['train_set']['RandomForestClassifier'] = np.round(score_train, 3)\n",
    "results_dict['test_set']['RandomForestClassifier'] = np.round(score_test, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CatBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate set to 0.347698\n",
      "0:\tlearn: 0.4088747\ttotal: 1.33s\tremaining: 4m 25s\n",
      "1:\tlearn: 0.3050586\ttotal: 2.36s\tremaining: 3m 53s\n",
      "2:\tlearn: 0.2618436\ttotal: 3.36s\tremaining: 3m 40s\n",
      "3:\tlearn: 0.2376257\ttotal: 4.31s\tremaining: 3m 31s\n",
      "4:\tlearn: 0.2264343\ttotal: 5.26s\tremaining: 3m 25s\n",
      "5:\tlearn: 0.2187414\ttotal: 6.2s\tremaining: 3m 20s\n",
      "6:\tlearn: 0.2133123\ttotal: 7.11s\tremaining: 3m 15s\n",
      "7:\tlearn: 0.2085965\ttotal: 8.07s\tremaining: 3m 13s\n",
      "8:\tlearn: 0.2037518\ttotal: 8.99s\tremaining: 3m 10s\n",
      "9:\tlearn: 0.2001982\ttotal: 9.92s\tremaining: 3m 8s\n",
      "10:\tlearn: 0.1960476\ttotal: 10.9s\tremaining: 3m 8s\n",
      "11:\tlearn: 0.1933418\ttotal: 11.9s\tremaining: 3m 6s\n",
      "12:\tlearn: 0.1906938\ttotal: 12.9s\tremaining: 3m 5s\n",
      "13:\tlearn: 0.1884155\ttotal: 13.9s\tremaining: 3m 4s\n",
      "14:\tlearn: 0.1863506\ttotal: 14.8s\tremaining: 3m 3s\n",
      "15:\tlearn: 0.1839878\ttotal: 15.8s\tremaining: 3m 1s\n",
      "16:\tlearn: 0.1818206\ttotal: 16.7s\tremaining: 3m\n",
      "17:\tlearn: 0.1800774\ttotal: 17.6s\tremaining: 2m 58s\n",
      "18:\tlearn: 0.1786581\ttotal: 18.5s\tremaining: 2m 56s\n",
      "19:\tlearn: 0.1773197\ttotal: 19.5s\tremaining: 2m 55s\n",
      "20:\tlearn: 0.1760203\ttotal: 20.4s\tremaining: 2m 54s\n",
      "21:\tlearn: 0.1741580\ttotal: 21.4s\tremaining: 2m 53s\n",
      "22:\tlearn: 0.1728890\ttotal: 22.4s\tremaining: 2m 52s\n",
      "23:\tlearn: 0.1708825\ttotal: 23.4s\tremaining: 2m 51s\n",
      "24:\tlearn: 0.1689334\ttotal: 24.3s\tremaining: 2m 50s\n",
      "25:\tlearn: 0.1678649\ttotal: 25.2s\tremaining: 2m 48s\n",
      "26:\tlearn: 0.1667301\ttotal: 26.2s\tremaining: 2m 47s\n",
      "27:\tlearn: 0.1649801\ttotal: 27.2s\tremaining: 2m 47s\n",
      "28:\tlearn: 0.1638839\ttotal: 28.2s\tremaining: 2m 46s\n",
      "29:\tlearn: 0.1630193\ttotal: 29.1s\tremaining: 2m 44s\n",
      "30:\tlearn: 0.1621483\ttotal: 30s\tremaining: 2m 43s\n",
      "31:\tlearn: 0.1612364\ttotal: 31s\tremaining: 2m 42s\n",
      "32:\tlearn: 0.1604662\ttotal: 31.9s\tremaining: 2m 41s\n",
      "33:\tlearn: 0.1592035\ttotal: 32.8s\tremaining: 2m 40s\n",
      "34:\tlearn: 0.1583918\ttotal: 33.8s\tremaining: 2m 39s\n",
      "35:\tlearn: 0.1576496\ttotal: 34.7s\tremaining: 2m 37s\n",
      "36:\tlearn: 0.1562970\ttotal: 35.7s\tremaining: 2m 37s\n",
      "37:\tlearn: 0.1556081\ttotal: 36.6s\tremaining: 2m 36s\n",
      "38:\tlearn: 0.1548233\ttotal: 37.6s\tremaining: 2m 35s\n",
      "39:\tlearn: 0.1540903\ttotal: 38.5s\tremaining: 2m 33s\n",
      "40:\tlearn: 0.1534329\ttotal: 39.4s\tremaining: 2m 32s\n",
      "41:\tlearn: 0.1527663\ttotal: 40.4s\tremaining: 2m 31s\n",
      "42:\tlearn: 0.1519678\ttotal: 41.3s\tremaining: 2m 30s\n",
      "43:\tlearn: 0.1512022\ttotal: 42.3s\tremaining: 2m 29s\n",
      "44:\tlearn: 0.1505723\ttotal: 43.2s\tremaining: 2m 28s\n",
      "45:\tlearn: 0.1495957\ttotal: 44.1s\tremaining: 2m 27s\n",
      "46:\tlearn: 0.1489029\ttotal: 45.1s\tremaining: 2m 26s\n",
      "47:\tlearn: 0.1482969\ttotal: 46s\tremaining: 2m 25s\n",
      "48:\tlearn: 0.1476902\ttotal: 47s\tremaining: 2m 24s\n",
      "49:\tlearn: 0.1471360\ttotal: 47.9s\tremaining: 2m 23s\n",
      "50:\tlearn: 0.1464878\ttotal: 48.8s\tremaining: 2m 22s\n",
      "51:\tlearn: 0.1456584\ttotal: 49.8s\tremaining: 2m 21s\n",
      "52:\tlearn: 0.1450871\ttotal: 50.7s\tremaining: 2m 20s\n",
      "53:\tlearn: 0.1442223\ttotal: 51.6s\tremaining: 2m 19s\n",
      "54:\tlearn: 0.1436507\ttotal: 52.6s\tremaining: 2m 18s\n",
      "55:\tlearn: 0.1429917\ttotal: 53.6s\tremaining: 2m 17s\n",
      "56:\tlearn: 0.1425705\ttotal: 54.5s\tremaining: 2m 16s\n",
      "57:\tlearn: 0.1420541\ttotal: 55.4s\tremaining: 2m 15s\n",
      "58:\tlearn: 0.1416504\ttotal: 56.4s\tremaining: 2m 14s\n",
      "59:\tlearn: 0.1412537\ttotal: 57.3s\tremaining: 2m 13s\n",
      "60:\tlearn: 0.1409606\ttotal: 58.3s\tremaining: 2m 12s\n",
      "61:\tlearn: 0.1406046\ttotal: 59.2s\tremaining: 2m 11s\n",
      "62:\tlearn: 0.1400393\ttotal: 1m\tremaining: 2m 10s\n",
      "63:\tlearn: 0.1397441\ttotal: 1m 1s\tremaining: 2m 9s\n",
      "64:\tlearn: 0.1394893\ttotal: 1m 1s\tremaining: 2m 8s\n",
      "65:\tlearn: 0.1387750\ttotal: 1m 2s\tremaining: 2m 7s\n",
      "66:\tlearn: 0.1382723\ttotal: 1m 3s\tremaining: 2m 6s\n",
      "67:\tlearn: 0.1379755\ttotal: 1m 4s\tremaining: 2m 5s\n",
      "68:\tlearn: 0.1375940\ttotal: 1m 5s\tremaining: 2m 4s\n",
      "69:\tlearn: 0.1369812\ttotal: 1m 6s\tremaining: 2m 3s\n",
      "70:\tlearn: 0.1365701\ttotal: 1m 7s\tremaining: 2m 2s\n",
      "71:\tlearn: 0.1361251\ttotal: 1m 8s\tremaining: 2m 1s\n",
      "72:\tlearn: 0.1358737\ttotal: 1m 9s\tremaining: 2m\n",
      "73:\tlearn: 0.1354042\ttotal: 1m 10s\tremaining: 1m 59s\n",
      "74:\tlearn: 0.1351433\ttotal: 1m 11s\tremaining: 1m 58s\n",
      "75:\tlearn: 0.1348418\ttotal: 1m 12s\tremaining: 1m 57s\n",
      "76:\tlearn: 0.1344790\ttotal: 1m 13s\tremaining: 1m 57s\n",
      "77:\tlearn: 0.1339328\ttotal: 1m 14s\tremaining: 1m 56s\n",
      "78:\tlearn: 0.1334891\ttotal: 1m 15s\tremaining: 1m 55s\n",
      "79:\tlearn: 0.1331446\ttotal: 1m 16s\tremaining: 1m 54s\n",
      "80:\tlearn: 0.1329069\ttotal: 1m 17s\tremaining: 1m 53s\n",
      "81:\tlearn: 0.1325660\ttotal: 1m 18s\tremaining: 1m 52s\n",
      "82:\tlearn: 0.1320770\ttotal: 1m 18s\tremaining: 1m 51s\n",
      "83:\tlearn: 0.1316866\ttotal: 1m 19s\tremaining: 1m 50s\n",
      "84:\tlearn: 0.1313148\ttotal: 1m 20s\tremaining: 1m 49s\n",
      "85:\tlearn: 0.1310149\ttotal: 1m 21s\tremaining: 1m 48s\n",
      "86:\tlearn: 0.1306237\ttotal: 1m 22s\tremaining: 1m 47s\n",
      "87:\tlearn: 0.1302584\ttotal: 1m 23s\tremaining: 1m 46s\n",
      "88:\tlearn: 0.1300503\ttotal: 1m 24s\tremaining: 1m 45s\n",
      "89:\tlearn: 0.1298768\ttotal: 1m 25s\tremaining: 1m 44s\n",
      "90:\tlearn: 0.1296951\ttotal: 1m 26s\tremaining: 1m 43s\n",
      "91:\tlearn: 0.1294965\ttotal: 1m 27s\tremaining: 1m 42s\n",
      "92:\tlearn: 0.1293334\ttotal: 1m 28s\tremaining: 1m 41s\n",
      "93:\tlearn: 0.1290338\ttotal: 1m 29s\tremaining: 1m 40s\n",
      "94:\tlearn: 0.1286689\ttotal: 1m 30s\tremaining: 1m 40s\n",
      "95:\tlearn: 0.1284886\ttotal: 1m 31s\tremaining: 1m 39s\n",
      "96:\tlearn: 0.1283238\ttotal: 1m 32s\tremaining: 1m 38s\n",
      "97:\tlearn: 0.1281247\ttotal: 1m 33s\tremaining: 1m 37s\n",
      "98:\tlearn: 0.1278445\ttotal: 1m 34s\tremaining: 1m 36s\n",
      "99:\tlearn: 0.1275166\ttotal: 1m 35s\tremaining: 1m 35s\n",
      "100:\tlearn: 0.1270894\ttotal: 1m 36s\tremaining: 1m 34s\n",
      "101:\tlearn: 0.1267556\ttotal: 1m 37s\tremaining: 1m 33s\n",
      "102:\tlearn: 0.1264401\ttotal: 1m 38s\tremaining: 1m 33s\n",
      "103:\tlearn: 0.1259711\ttotal: 1m 39s\tremaining: 1m 32s\n",
      "104:\tlearn: 0.1257338\ttotal: 1m 40s\tremaining: 1m 31s\n",
      "105:\tlearn: 0.1255691\ttotal: 1m 41s\tremaining: 1m 30s\n",
      "106:\tlearn: 0.1254096\ttotal: 1m 42s\tremaining: 1m 29s\n",
      "107:\tlearn: 0.1252392\ttotal: 1m 44s\tremaining: 1m 28s\n",
      "108:\tlearn: 0.1249866\ttotal: 1m 45s\tremaining: 1m 27s\n",
      "109:\tlearn: 0.1248470\ttotal: 1m 45s\tremaining: 1m 26s\n",
      "110:\tlearn: 0.1245482\ttotal: 1m 47s\tremaining: 1m 25s\n",
      "111:\tlearn: 0.1242989\ttotal: 1m 48s\tremaining: 1m 24s\n",
      "112:\tlearn: 0.1240057\ttotal: 1m 49s\tremaining: 1m 24s\n",
      "113:\tlearn: 0.1238727\ttotal: 1m 50s\tremaining: 1m 23s\n",
      "114:\tlearn: 0.1237519\ttotal: 1m 50s\tremaining: 1m 21s\n",
      "115:\tlearn: 0.1232823\ttotal: 1m 51s\tremaining: 1m 21s\n",
      "116:\tlearn: 0.1229558\ttotal: 1m 53s\tremaining: 1m 20s\n",
      "117:\tlearn: 0.1228173\ttotal: 1m 53s\tremaining: 1m 19s\n",
      "118:\tlearn: 0.1225952\ttotal: 1m 55s\tremaining: 1m 18s\n",
      "119:\tlearn: 0.1224714\ttotal: 1m 56s\tremaining: 1m 17s\n",
      "120:\tlearn: 0.1219656\ttotal: 1m 57s\tremaining: 1m 16s\n",
      "121:\tlearn: 0.1215945\ttotal: 1m 58s\tremaining: 1m 15s\n",
      "122:\tlearn: 0.1214557\ttotal: 1m 59s\tremaining: 1m 14s\n",
      "123:\tlearn: 0.1212834\ttotal: 2m\tremaining: 1m 13s\n",
      "124:\tlearn: 0.1211652\ttotal: 2m 1s\tremaining: 1m 12s\n",
      "125:\tlearn: 0.1209995\ttotal: 2m 2s\tremaining: 1m 11s\n",
      "126:\tlearn: 0.1208772\ttotal: 2m 3s\tremaining: 1m 10s\n",
      "127:\tlearn: 0.1207413\ttotal: 2m 4s\tremaining: 1m 9s\n",
      "128:\tlearn: 0.1204880\ttotal: 2m 5s\tremaining: 1m 8s\n",
      "129:\tlearn: 0.1202076\ttotal: 2m 6s\tremaining: 1m 8s\n",
      "130:\tlearn: 0.1198868\ttotal: 2m 7s\tremaining: 1m 7s\n",
      "131:\tlearn: 0.1196773\ttotal: 2m 8s\tremaining: 1m 6s\n",
      "132:\tlearn: 0.1192934\ttotal: 2m 9s\tremaining: 1m 5s\n",
      "133:\tlearn: 0.1191687\ttotal: 2m 10s\tremaining: 1m 4s\n",
      "134:\tlearn: 0.1187231\ttotal: 2m 11s\tremaining: 1m 3s\n",
      "135:\tlearn: 0.1186023\ttotal: 2m 12s\tremaining: 1m 2s\n",
      "136:\tlearn: 0.1184852\ttotal: 2m 13s\tremaining: 1m 1s\n",
      "137:\tlearn: 0.1183082\ttotal: 2m 14s\tremaining: 1m\n",
      "138:\tlearn: 0.1181878\ttotal: 2m 15s\tremaining: 59.6s\n",
      "139:\tlearn: 0.1180776\ttotal: 2m 16s\tremaining: 58.6s\n",
      "140:\tlearn: 0.1178927\ttotal: 2m 17s\tremaining: 57.6s\n",
      "141:\tlearn: 0.1177827\ttotal: 2m 18s\tremaining: 56.7s\n",
      "142:\tlearn: 0.1174242\ttotal: 2m 19s\tremaining: 55.7s\n",
      "143:\tlearn: 0.1173201\ttotal: 2m 20s\tremaining: 54.7s\n",
      "144:\tlearn: 0.1170670\ttotal: 2m 21s\tremaining: 53.8s\n",
      "145:\tlearn: 0.1169687\ttotal: 2m 22s\tremaining: 52.8s\n",
      "146:\tlearn: 0.1168751\ttotal: 2m 23s\tremaining: 51.8s\n",
      "147:\tlearn: 0.1166685\ttotal: 2m 24s\tremaining: 50.9s\n",
      "148:\tlearn: 0.1165690\ttotal: 2m 25s\tremaining: 49.9s\n",
      "149:\tlearn: 0.1163338\ttotal: 2m 26s\tremaining: 48.9s\n",
      "150:\tlearn: 0.1160968\ttotal: 2m 27s\tremaining: 48s\n",
      "151:\tlearn: 0.1158187\ttotal: 2m 28s\tremaining: 47s\n",
      "152:\tlearn: 0.1155592\ttotal: 2m 29s\tremaining: 46.1s\n",
      "153:\tlearn: 0.1154478\ttotal: 2m 30s\tremaining: 45.1s\n",
      "154:\tlearn: 0.1152061\ttotal: 2m 31s\tremaining: 44.1s\n",
      "155:\tlearn: 0.1151013\ttotal: 2m 33s\tremaining: 43.2s\n",
      "156:\tlearn: 0.1149731\ttotal: 2m 34s\tremaining: 42.2s\n",
      "157:\tlearn: 0.1148805\ttotal: 2m 35s\tremaining: 41.2s\n",
      "158:\tlearn: 0.1147767\ttotal: 2m 36s\tremaining: 40.3s\n",
      "159:\tlearn: 0.1146804\ttotal: 2m 37s\tremaining: 39.3s\n",
      "160:\tlearn: 0.1144871\ttotal: 2m 38s\tremaining: 38.3s\n",
      "161:\tlearn: 0.1143918\ttotal: 2m 39s\tremaining: 37.3s\n",
      "162:\tlearn: 0.1143074\ttotal: 2m 40s\tremaining: 36.3s\n",
      "163:\tlearn: 0.1142183\ttotal: 2m 41s\tremaining: 35.4s\n",
      "164:\tlearn: 0.1140285\ttotal: 2m 42s\tremaining: 34.4s\n",
      "165:\tlearn: 0.1138018\ttotal: 2m 43s\tremaining: 33.4s\n",
      "166:\tlearn: 0.1136702\ttotal: 2m 44s\tremaining: 32.5s\n",
      "167:\tlearn: 0.1134550\ttotal: 2m 45s\tremaining: 31.5s\n",
      "168:\tlearn: 0.1132107\ttotal: 2m 46s\tremaining: 30.5s\n",
      "169:\tlearn: 0.1131101\ttotal: 2m 47s\tremaining: 29.5s\n",
      "170:\tlearn: 0.1128942\ttotal: 2m 48s\tremaining: 28.6s\n",
      "171:\tlearn: 0.1125787\ttotal: 2m 49s\tremaining: 27.6s\n",
      "172:\tlearn: 0.1124919\ttotal: 2m 50s\tremaining: 26.6s\n",
      "173:\tlearn: 0.1124063\ttotal: 2m 51s\tremaining: 25.6s\n",
      "174:\tlearn: 0.1122767\ttotal: 2m 52s\tremaining: 24.6s\n",
      "175:\tlearn: 0.1121896\ttotal: 2m 53s\tremaining: 23.6s\n",
      "176:\tlearn: 0.1121061\ttotal: 2m 54s\tremaining: 22.6s\n",
      "177:\tlearn: 0.1120291\ttotal: 2m 55s\tremaining: 21.7s\n",
      "178:\tlearn: 0.1119501\ttotal: 2m 56s\tremaining: 20.7s\n",
      "179:\tlearn: 0.1118645\ttotal: 2m 57s\tremaining: 19.7s\n",
      "180:\tlearn: 0.1117757\ttotal: 2m 58s\tremaining: 18.7s\n",
      "181:\tlearn: 0.1116066\ttotal: 2m 59s\tremaining: 17.8s\n",
      "182:\tlearn: 0.1115091\ttotal: 3m\tremaining: 16.8s\n",
      "183:\tlearn: 0.1114132\ttotal: 3m 1s\tremaining: 15.8s\n",
      "184:\tlearn: 0.1113070\ttotal: 3m 2s\tremaining: 14.8s\n",
      "185:\tlearn: 0.1110974\ttotal: 3m 3s\tremaining: 13.8s\n",
      "186:\tlearn: 0.1110178\ttotal: 3m 4s\tremaining: 12.8s\n",
      "187:\tlearn: 0.1107672\ttotal: 3m 5s\tremaining: 11.8s\n",
      "188:\tlearn: 0.1105872\ttotal: 3m 6s\tremaining: 10.9s\n",
      "189:\tlearn: 0.1105034\ttotal: 3m 7s\tremaining: 9.88s\n",
      "190:\tlearn: 0.1104225\ttotal: 3m 8s\tremaining: 8.89s\n",
      "191:\tlearn: 0.1101534\ttotal: 3m 9s\tremaining: 7.91s\n",
      "192:\tlearn: 0.1100827\ttotal: 3m 10s\tremaining: 6.92s\n",
      "193:\tlearn: 0.1098718\ttotal: 3m 11s\tremaining: 5.93s\n",
      "194:\tlearn: 0.1097950\ttotal: 3m 12s\tremaining: 4.95s\n",
      "195:\tlearn: 0.1095546\ttotal: 3m 13s\tremaining: 3.96s\n",
      "196:\tlearn: 0.1094669\ttotal: 3m 14s\tremaining: 2.97s\n",
      "197:\tlearn: 0.1093607\ttotal: 3m 16s\tremaining: 1.98s\n",
      "198:\tlearn: 0.1092482\ttotal: 3m 16s\tremaining: 990ms\n",
      "199:\tlearn: 0.1090525\ttotal: 3m 17s\tremaining: 0us\n",
      "Predictions shape on train set -  (119678,)\n",
      "F1-score on train set -  0.7876470025815088\n",
      "Wall time: 3min 30s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "ctb_clf = ctb.CatBoostClassifier(iterations=200, random_state=1)\n",
    "\n",
    "ctb_clf.fit(tf_idf_train, y_train)\n",
    "pred_train = ctb_clf.predict(tf_idf_train)\n",
    "\n",
    "score_train = f1_score(pred_train, y_train)\n",
    "\n",
    "print('Predictions shape on train set - ', pred_train.shape)\n",
    "print('F1-score on train set - ', score_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions shape on test set -  (39893,)\n",
      "F1-score on test set -  0.7476020042949177\n"
     ]
    }
   ],
   "source": [
    "pred_test = ctb_clf.predict(tf_idf_test)\n",
    "\n",
    "score_test = f1_score(pred_test, y_test)\n",
    "\n",
    "print('Predictions shape on test set - ', pred_test.shape)\n",
    "print('F1-score on test set - ', score_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_dict['train_set']['CatBoostClassifier'] = np.round(score_train, 3)\n",
    "results_dict['test_set']['CatBoostClassifier'] = np.round(score_test, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LGBMClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions shape on train set -  (119678,)\n",
      "F1-score on train set -  0.7780888030888032\n",
      "Wall time: 29.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "lgb_clf = lgb.LGBMClassifier(random_state=1)\n",
    "\n",
    "lgb_clf.fit(tf_idf_train, y_train)\n",
    "pred_train = lgb_clf.predict(tf_idf_train)\n",
    "\n",
    "score_train = f1_score(pred_train, y_train)\n",
    "\n",
    "print('Predictions shape on train set - ', pred_train.shape)\n",
    "print('F1-score on train set - ', score_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions shape on test set -  (39893,)\n",
      "F1-score on test set -  0.7506778935350363\n"
     ]
    }
   ],
   "source": [
    "pred_test = lgb_clf.predict(tf_idf_test)\n",
    "\n",
    "score_test = f1_score(pred_test, y_test)\n",
    "\n",
    "print('Predictions shape on test set - ', pred_test.shape)\n",
    "print('F1-score on test set - ', score_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_dict['train_set']['LGBMClassifier'] = np.round(score_train, 3)\n",
    "results_dict['test_set']['LGBMClassifier'] = np.round(score_test, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Итоги исследования"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Итоговые результаты обучения и тестирования моделей: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train_set</th>\n",
       "      <th>test_set</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>LogisticRegression</th>\n",
       "      <td>0.760</td>\n",
       "      <td>0.732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RandomForestClassifier</th>\n",
       "      <td>0.998</td>\n",
       "      <td>0.699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CatBoostClassifier</th>\n",
       "      <td>0.788</td>\n",
       "      <td>0.748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LGBMClassifier</th>\n",
       "      <td>0.778</td>\n",
       "      <td>0.751</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        train_set  test_set\n",
       "LogisticRegression          0.760     0.732\n",
       "RandomForestClassifier      0.998     0.699\n",
       "CatBoostClassifier          0.788     0.748\n",
       "LGBMClassifier              0.778     0.751"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Итоговые результаты обучения и тестирования моделей: ')\n",
    "pd.DataFrame(results_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Проект для «Викишоп»** - исследовательский проект, целью которого - построить модель классификации комментариев на позитивные и негативныесо значением метрики качества F1 не меньше 0.75.\n",
    "\n",
    "Для достижения указанной цели были решены следующие задачи:\n",
    "1. Загрузите и подготовьте данные.\n",
    "В рамках подготовки выполнено:\n",
    "* Очистка от ненужных символов, приведение к нижнему регистру\n",
    "* Лемматизация текста\n",
    "* Содан мешок слов с исключением стоп-слов\n",
    "* Данные разбиты на обучающую, тестовую выборки, произведен скоринг векторов слов методом TF-IDF\n",
    "2. Обучены разные модели: LogisticRegression, RandomForestClassifier, CatBoostClassifier, LGBMClassifier - и рассчитана итоговая метрика качества F1 на обучающей и тестовой выборки. \n",
    "3. Результаты обучения и предсказаний показали, что: \n",
    "* все модели оказались переобучены в той или иной степени: необходимо ограничивать степень обучения и подбирать гиперпараметры;\n",
    "* наилучшие результаты на тестовой выборке показала `LGBMClassifier\t(F1-score - 0.751)`\n",
    "* Стоит отметить, что модели CatBoostClassifier (F1-score - 0.748) и  LogisticRegression тоже показала хорошие результаты (F1-score - 0.732)\n",
    "* Наихудшей как с точки зрения времени обучения, так и с точки зрения итоговой метрики качества оказалась модель RandomForestClassifier\t(F1-score - 0.699)."
   ]
  }
 ],
 "metadata": {
  "ExecuteTimeLog": [
   {
    "duration": 637,
    "start_time": "2022-05-19T07:12:36.159Z"
   },
   {
    "duration": 83,
    "start_time": "2022-05-19T07:13:30.770Z"
   },
   {
    "duration": 43,
    "start_time": "2022-05-19T07:13:46.916Z"
   },
   {
    "duration": 4592,
    "start_time": "2022-05-19T07:18:07.445Z"
   },
   {
    "duration": 1016,
    "start_time": "2022-05-19T07:20:39.267Z"
   },
   {
    "duration": 848,
    "start_time": "2022-05-19T07:20:45.854Z"
   },
   {
    "duration": 893,
    "start_time": "2022-05-19T07:20:57.255Z"
   },
   {
    "duration": 7,
    "start_time": "2022-05-19T07:21:10.625Z"
   },
   {
    "duration": 45,
    "start_time": "2022-05-19T07:23:53.024Z"
   },
   {
    "duration": 23,
    "start_time": "2022-05-19T07:23:58.488Z"
   },
   {
    "duration": 22,
    "start_time": "2022-05-19T07:24:19.992Z"
   },
   {
    "duration": 37,
    "start_time": "2022-05-19T07:24:34.928Z"
   },
   {
    "duration": 23,
    "start_time": "2022-05-19T07:24:50.776Z"
   },
   {
    "duration": 32,
    "start_time": "2022-05-19T07:25:05.042Z"
   },
   {
    "duration": 22,
    "start_time": "2022-05-19T07:25:13.566Z"
   },
   {
    "duration": 3944,
    "start_time": "2022-05-19T08:59:34.659Z"
   },
   {
    "duration": 9361,
    "start_time": "2022-05-19T09:01:05.106Z"
   },
   {
    "duration": 4161,
    "start_time": "2022-05-19T09:01:56.469Z"
   },
   {
    "duration": 1064,
    "start_time": "2022-05-19T09:02:00.632Z"
   },
   {
    "duration": 16,
    "start_time": "2022-05-19T09:02:01.699Z"
   },
   {
    "duration": 3608,
    "start_time": "2022-05-20T06:47:05.083Z"
   },
   {
    "duration": 3459,
    "start_time": "2022-05-20T06:47:08.694Z"
   },
   {
    "duration": 15,
    "start_time": "2022-05-20T06:47:12.159Z"
   },
   {
    "duration": 1085,
    "start_time": "2022-05-20T06:51:54.707Z"
   },
   {
    "duration": 128,
    "start_time": "2022-05-20T07:17:21.973Z"
   },
   {
    "duration": 8,
    "start_time": "2022-05-20T07:17:39.924Z"
   },
   {
    "duration": 879,
    "start_time": "2022-05-20T07:17:48.814Z"
   },
   {
    "duration": 3999,
    "start_time": "2022-05-20T07:17:49.695Z"
   },
   {
    "duration": 13,
    "start_time": "2022-05-20T07:17:53.696Z"
   },
   {
    "duration": 41,
    "start_time": "2022-05-20T07:17:53.711Z"
   },
   {
    "duration": 136,
    "start_time": "2022-05-20T07:17:53.755Z"
   },
   {
    "duration": 0,
    "start_time": "2022-05-20T07:17:53.893Z"
   },
   {
    "duration": 0,
    "start_time": "2022-05-20T07:17:53.894Z"
   },
   {
    "duration": 0,
    "start_time": "2022-05-20T07:17:53.895Z"
   },
   {
    "duration": 100,
    "start_time": "2022-05-20T07:20:56.980Z"
   },
   {
    "duration": 1084,
    "start_time": "2022-05-20T07:21:00.562Z"
   },
   {
    "duration": 71,
    "start_time": "2022-05-20T07:21:03.106Z"
   },
   {
    "duration": 15,
    "start_time": "2022-05-20T07:21:06.754Z"
   },
   {
    "duration": 950,
    "start_time": "2022-05-20T07:21:11.541Z"
   },
   {
    "duration": 3714,
    "start_time": "2022-05-20T07:21:12.493Z"
   },
   {
    "duration": 14,
    "start_time": "2022-05-20T07:21:16.209Z"
   },
   {
    "duration": 42,
    "start_time": "2022-05-20T07:21:16.225Z"
   },
   {
    "duration": 976,
    "start_time": "2022-05-20T07:25:38.724Z"
   },
   {
    "duration": 3578,
    "start_time": "2022-05-20T07:25:39.702Z"
   },
   {
    "duration": 12,
    "start_time": "2022-05-20T07:25:43.281Z"
   },
   {
    "duration": 31,
    "start_time": "2022-05-20T07:25:43.294Z"
   },
   {
    "duration": 1048,
    "start_time": "2022-05-20T07:28:09.459Z"
   },
   {
    "duration": 3587,
    "start_time": "2022-05-20T07:28:10.509Z"
   },
   {
    "duration": 15,
    "start_time": "2022-05-20T07:28:14.098Z"
   },
   {
    "duration": 5,
    "start_time": "2022-05-20T07:28:14.114Z"
   },
   {
    "duration": 59,
    "start_time": "2022-05-20T07:28:14.121Z"
   },
   {
    "duration": 4,
    "start_time": "2022-05-20T07:28:14.182Z"
   },
   {
    "duration": 4,
    "start_time": "2022-05-20T07:28:14.189Z"
   },
   {
    "duration": 4,
    "start_time": "2022-05-20T07:28:14.195Z"
   },
   {
    "duration": 833,
    "start_time": "2022-05-20T07:28:38.874Z"
   },
   {
    "duration": 36,
    "start_time": "2022-05-20T07:28:49.079Z"
   },
   {
    "duration": 997,
    "start_time": "2022-05-20T07:28:56.358Z"
   },
   {
    "duration": 1025,
    "start_time": "2022-05-20T07:28:57.358Z"
   },
   {
    "duration": 14,
    "start_time": "2022-05-20T07:28:58.386Z"
   },
   {
    "duration": 55,
    "start_time": "2022-05-20T07:28:58.402Z"
   },
   {
    "duration": 1033,
    "start_time": "2022-05-20T07:31:06.661Z"
   },
   {
    "duration": 3715,
    "start_time": "2022-05-20T07:31:07.696Z"
   },
   {
    "duration": 15,
    "start_time": "2022-05-20T07:31:11.413Z"
   },
   {
    "duration": 15,
    "start_time": "2022-05-20T07:31:11.431Z"
   },
   {
    "duration": 616,
    "start_time": "2022-05-20T07:31:11.452Z"
   },
   {
    "duration": 5,
    "start_time": "2022-05-20T07:31:12.069Z"
   },
   {
    "duration": 10,
    "start_time": "2022-05-20T07:31:12.075Z"
   },
   {
    "duration": 11,
    "start_time": "2022-05-20T07:31:12.087Z"
   },
   {
    "duration": 954,
    "start_time": "2022-05-20T07:31:29.179Z"
   },
   {
    "duration": 1095,
    "start_time": "2022-05-20T07:31:30.134Z"
   },
   {
    "duration": 27,
    "start_time": "2022-05-20T07:31:31.231Z"
   },
   {
    "duration": 36,
    "start_time": "2022-05-20T07:31:31.263Z"
   },
   {
    "duration": 962,
    "start_time": "2022-05-20T07:31:55.986Z"
   },
   {
    "duration": 4033,
    "start_time": "2022-05-20T07:31:56.953Z"
   },
   {
    "duration": 16,
    "start_time": "2022-05-20T07:32:00.989Z"
   },
   {
    "duration": 55,
    "start_time": "2022-05-20T07:32:01.007Z"
   },
   {
    "duration": 1003,
    "start_time": "2022-05-20T07:32:24.211Z"
   },
   {
    "duration": 3808,
    "start_time": "2022-05-20T07:32:25.216Z"
   },
   {
    "duration": 15,
    "start_time": "2022-05-20T07:32:29.025Z"
   },
   {
    "duration": 20,
    "start_time": "2022-05-20T07:32:29.047Z"
   },
   {
    "duration": 970,
    "start_time": "2022-05-20T07:32:46.305Z"
   },
   {
    "duration": 3721,
    "start_time": "2022-05-20T07:32:47.278Z"
   },
   {
    "duration": 14,
    "start_time": "2022-05-20T07:32:51.001Z"
   },
   {
    "duration": 14,
    "start_time": "2022-05-20T07:32:51.017Z"
   },
   {
    "duration": 4464,
    "start_time": "2022-05-20T07:32:51.033Z"
   },
   {
    "duration": 6,
    "start_time": "2022-05-20T07:32:55.499Z"
   },
   {
    "duration": 5,
    "start_time": "2022-05-20T07:32:55.506Z"
   },
   {
    "duration": 7,
    "start_time": "2022-05-20T07:32:55.513Z"
   },
   {
    "duration": 973,
    "start_time": "2022-05-20T07:33:08.205Z"
   },
   {
    "duration": 1015,
    "start_time": "2022-05-20T07:33:09.180Z"
   },
   {
    "duration": 16,
    "start_time": "2022-05-20T07:33:10.197Z"
   },
   {
    "duration": 35,
    "start_time": "2022-05-20T07:33:10.216Z"
   },
   {
    "duration": 956,
    "start_time": "2022-05-20T07:33:26.264Z"
   },
   {
    "duration": 3661,
    "start_time": "2022-05-20T07:33:27.222Z"
   },
   {
    "duration": 13,
    "start_time": "2022-05-20T07:33:30.885Z"
   },
   {
    "duration": 13,
    "start_time": "2022-05-20T07:33:30.899Z"
   },
   {
    "duration": 4411,
    "start_time": "2022-05-20T07:33:30.914Z"
   },
   {
    "duration": 4,
    "start_time": "2022-05-20T07:33:35.327Z"
   },
   {
    "duration": 2,
    "start_time": "2022-05-20T07:33:35.341Z"
   },
   {
    "duration": 17,
    "start_time": "2022-05-20T07:33:35.345Z"
   },
   {
    "duration": 10,
    "start_time": "2022-05-20T07:38:26.558Z"
   },
   {
    "duration": 4,
    "start_time": "2022-05-20T07:38:32.781Z"
   },
   {
    "duration": 4,
    "start_time": "2022-05-20T07:38:56.310Z"
   },
   {
    "duration": 5,
    "start_time": "2022-05-20T07:39:02.948Z"
   },
   {
    "duration": 5,
    "start_time": "2022-05-20T07:39:06.229Z"
   },
   {
    "duration": 1427,
    "start_time": "2022-05-20T07:41:47.589Z"
   },
   {
    "duration": 4540,
    "start_time": "2022-05-20T07:41:49.018Z"
   },
   {
    "duration": 19,
    "start_time": "2022-05-20T07:41:53.564Z"
   },
   {
    "duration": 11,
    "start_time": "2022-05-20T07:41:53.585Z"
   },
   {
    "duration": 5096,
    "start_time": "2022-05-20T07:41:53.598Z"
   },
   {
    "duration": 79,
    "start_time": "2022-05-20T07:42:09.212Z"
   },
   {
    "duration": 1641,
    "start_time": "2022-05-20T07:42:22.753Z"
   },
   {
    "duration": 4352,
    "start_time": "2022-05-20T07:42:24.396Z"
   },
   {
    "duration": 18,
    "start_time": "2022-05-20T07:42:28.750Z"
   },
   {
    "duration": 24,
    "start_time": "2022-05-20T07:42:28.772Z"
   },
   {
    "duration": 5139,
    "start_time": "2022-05-20T07:42:28.798Z"
   },
   {
    "duration": 487,
    "start_time": "2022-05-20T07:42:33.940Z"
   },
   {
    "duration": 1464,
    "start_time": "2022-05-20T07:42:45.591Z"
   },
   {
    "duration": 4440,
    "start_time": "2022-05-20T07:42:47.059Z"
   },
   {
    "duration": 15,
    "start_time": "2022-05-20T07:42:51.501Z"
   },
   {
    "duration": 8,
    "start_time": "2022-05-20T07:42:51.518Z"
   },
   {
    "duration": 1394,
    "start_time": "2022-05-20T07:42:51.528Z"
   },
   {
    "duration": 159,
    "start_time": "2022-05-20T07:42:52.924Z"
   },
   {
    "duration": 309,
    "start_time": "2022-05-20T07:42:53.085Z"
   },
   {
    "duration": 4,
    "start_time": "2022-05-20T07:42:53.396Z"
   },
   {
    "duration": 5,
    "start_time": "2022-05-20T07:44:04.179Z"
   },
   {
    "duration": 34270,
    "start_time": "2022-05-20T07:45:06.809Z"
   },
   {
    "duration": 272,
    "start_time": "2022-05-20T07:48:10.687Z"
   },
   {
    "duration": 317,
    "start_time": "2022-05-20T07:53:38.919Z"
   },
   {
    "duration": 35503,
    "start_time": "2022-05-20T07:56:35.471Z"
   },
   {
    "duration": 960,
    "start_time": "2022-05-20T08:00:27.722Z"
   },
   {
    "duration": 3074,
    "start_time": "2022-05-20T08:00:28.684Z"
   },
   {
    "duration": 12,
    "start_time": "2022-05-20T08:00:31.761Z"
   },
   {
    "duration": 13,
    "start_time": "2022-05-20T08:00:31.775Z"
   },
   {
    "duration": 1207,
    "start_time": "2022-05-20T08:00:31.791Z"
   },
   {
    "duration": 371,
    "start_time": "2022-05-20T08:00:32.999Z"
   },
   {
    "duration": 4,
    "start_time": "2022-05-20T08:00:33.371Z"
   },
   {
    "duration": 29323,
    "start_time": "2022-05-20T08:00:33.377Z"
   },
   {
    "duration": 296,
    "start_time": "2022-05-20T08:01:02.703Z"
   },
   {
    "duration": 997,
    "start_time": "2022-05-20T08:05:46.208Z"
   },
   {
    "duration": 1002,
    "start_time": "2022-05-20T08:05:47.208Z"
   },
   {
    "duration": 15,
    "start_time": "2022-05-20T08:05:48.212Z"
   },
   {
    "duration": 11,
    "start_time": "2022-05-20T08:05:48.229Z"
   },
   {
    "duration": 1259,
    "start_time": "2022-05-20T08:05:48.242Z"
   },
   {
    "duration": 403,
    "start_time": "2022-05-20T08:05:49.503Z"
   },
   {
    "duration": 5,
    "start_time": "2022-05-20T08:05:49.907Z"
   },
   {
    "duration": 1021,
    "start_time": "2022-05-20T08:06:04.379Z"
   },
   {
    "duration": 978,
    "start_time": "2022-05-20T08:06:05.401Z"
   },
   {
    "duration": 14,
    "start_time": "2022-05-20T08:06:06.381Z"
   },
   {
    "duration": 21,
    "start_time": "2022-05-20T08:06:06.397Z"
   },
   {
    "duration": 1329,
    "start_time": "2022-05-20T08:06:06.419Z"
   },
   {
    "duration": 396,
    "start_time": "2022-05-20T08:06:07.749Z"
   },
   {
    "duration": 4,
    "start_time": "2022-05-20T08:06:08.147Z"
   },
   {
    "duration": 29843,
    "start_time": "2022-05-20T08:06:08.153Z"
   },
   {
    "duration": 301,
    "start_time": "2022-05-20T08:06:37.999Z"
   },
   {
    "duration": 244702,
    "start_time": "2022-05-20T08:11:38.680Z"
   },
   {
    "duration": 31044,
    "start_time": "2022-05-20T08:15:43.383Z"
   },
   {
    "duration": 217,
    "start_time": "2022-05-20T08:16:52.615Z"
   },
   {
    "duration": 112,
    "start_time": "2022-05-20T08:20:57.906Z"
   },
   {
    "duration": 0,
    "start_time": "2022-05-20T08:20:58.019Z"
   },
   {
    "duration": 59420,
    "start_time": "2022-05-20T08:21:11.694Z"
   },
   {
    "duration": 379,
    "start_time": "2022-05-20T08:22:11.116Z"
   },
   {
    "duration": 30,
    "start_time": "2022-05-20T08:25:25.780Z"
   },
   {
    "duration": 126087,
    "start_time": "2022-05-20T08:26:37.457Z"
   },
   {
    "duration": 581,
    "start_time": "2022-05-20T08:28:43.546Z"
   },
   {
    "duration": 162,
    "start_time": "2022-05-20T08:43:32.561Z"
   },
   {
    "duration": 14,
    "start_time": "2022-05-20T08:44:58.577Z"
   },
   {
    "duration": 952,
    "start_time": "2022-05-20T08:45:08.041Z"
   },
   {
    "duration": 333,
    "start_time": "2022-05-20T10:36:21.253Z"
   },
   {
    "duration": 3,
    "start_time": "2022-05-20T10:48:13.699Z"
   },
   {
    "duration": 3,
    "start_time": "2022-05-20T10:50:12.692Z"
   },
   {
    "duration": 223,
    "start_time": "2022-05-20T10:50:22.211Z"
   },
   {
    "duration": 10,
    "start_time": "2022-05-20T11:22:41.295Z"
   },
   {
    "duration": 9,
    "start_time": "2022-05-20T11:22:55.904Z"
   },
   {
    "duration": 9,
    "start_time": "2022-05-20T11:22:58.548Z"
   },
   {
    "duration": 506,
    "start_time": "2022-05-20T11:23:10.556Z"
   },
   {
    "duration": 13,
    "start_time": "2022-05-20T11:23:18.548Z"
   },
   {
    "duration": 6,
    "start_time": "2022-05-20T11:23:21.395Z"
   },
   {
    "duration": 32,
    "start_time": "2022-05-20T11:25:42.023Z"
   },
   {
    "duration": 15,
    "start_time": "2022-05-20T11:26:10.654Z"
   },
   {
    "duration": 11,
    "start_time": "2022-05-20T11:26:19.648Z"
   },
   {
    "duration": 16,
    "start_time": "2022-05-20T11:26:42.291Z"
   },
   {
    "duration": 34,
    "start_time": "2022-05-20T11:27:07.068Z"
   },
   {
    "duration": 12,
    "start_time": "2022-05-20T11:33:16.635Z"
   },
   {
    "duration": 4,
    "start_time": "2022-05-20T11:34:38.522Z"
   },
   {
    "duration": 11,
    "start_time": "2022-05-20T11:35:46.155Z"
   },
   {
    "duration": 26,
    "start_time": "2022-05-20T11:35:59.650Z"
   },
   {
    "duration": 20,
    "start_time": "2022-05-20T11:36:27.267Z"
   },
   {
    "duration": 18,
    "start_time": "2022-05-20T11:36:42.062Z"
   },
   {
    "duration": 3,
    "start_time": "2022-05-20T11:37:01.187Z"
   },
   {
    "duration": 1177,
    "start_time": "2022-05-20T11:37:31.449Z"
   },
   {
    "duration": 545,
    "start_time": "2022-05-20T11:38:15.609Z"
   },
   {
    "duration": 4,
    "start_time": "2022-05-20T11:39:20.110Z"
   },
   {
    "duration": 4863,
    "start_time": "2022-05-20T11:40:06.385Z"
   },
   {
    "duration": 4,
    "start_time": "2022-05-20T11:40:21.897Z"
   },
   {
    "duration": 2099,
    "start_time": "2022-05-20T11:40:36.824Z"
   },
   {
    "duration": 6047,
    "start_time": "2022-05-20T11:40:55.873Z"
   },
   {
    "duration": 678,
    "start_time": "2022-05-20T11:41:03.512Z"
   },
   {
    "duration": 10,
    "start_time": "2022-05-20T11:41:16.208Z"
   },
   {
    "duration": 6037,
    "start_time": "2022-05-20T11:41:30.410Z"
   },
   {
    "duration": 8,
    "start_time": "2022-05-20T11:41:38.032Z"
   },
   {
    "duration": 754,
    "start_time": "2022-05-20T11:42:34.232Z"
   },
   {
    "duration": 4,
    "start_time": "2022-05-20T11:42:41.770Z"
   },
   {
    "duration": 9,
    "start_time": "2022-05-20T11:42:49.647Z"
   },
   {
    "duration": 6724,
    "start_time": "2022-05-20T11:46:05.196Z"
   },
   {
    "duration": 758,
    "start_time": "2022-05-20T11:46:17.510Z"
   },
   {
    "duration": 6,
    "start_time": "2022-05-20T11:48:40.106Z"
   },
   {
    "duration": 4,
    "start_time": "2022-05-20T11:48:43.662Z"
   },
   {
    "duration": 5,
    "start_time": "2022-05-20T11:48:46.100Z"
   },
   {
    "duration": 127,
    "start_time": "2022-05-20T11:49:51.824Z"
   },
   {
    "duration": 11,
    "start_time": "2022-05-20T11:49:56.496Z"
   },
   {
    "duration": 12,
    "start_time": "2022-05-20T11:50:05.558Z"
   },
   {
    "duration": 4,
    "start_time": "2022-05-20T11:50:23.031Z"
   },
   {
    "duration": 6111,
    "start_time": "2022-05-20T11:50:35.006Z"
   },
   {
    "duration": 704,
    "start_time": "2022-05-20T11:50:59.982Z"
   },
   {
    "duration": 4,
    "start_time": "2022-05-20T11:53:41.158Z"
   },
   {
    "duration": 4,
    "start_time": "2022-05-20T11:53:51.781Z"
   },
   {
    "duration": 4,
    "start_time": "2022-05-20T11:54:14.468Z"
   },
   {
    "duration": 1652,
    "start_time": "2022-05-20T11:56:48.107Z"
   },
   {
    "duration": 5,
    "start_time": "2022-05-20T12:02:57.253Z"
   },
   {
    "duration": 4,
    "start_time": "2022-05-20T12:04:59.016Z"
   },
   {
    "duration": 2,
    "start_time": "2022-05-20T12:19:59.828Z"
   },
   {
    "duration": 19,
    "start_time": "2022-05-20T12:20:36.809Z"
   },
   {
    "duration": 836,
    "start_time": "2022-05-20T12:20:56.924Z"
   },
   {
    "duration": 2,
    "start_time": "2022-05-20T12:21:09.173Z"
   },
   {
    "duration": 6,
    "start_time": "2022-05-20T12:21:10.242Z"
   },
   {
    "duration": 6,
    "start_time": "2022-05-20T12:32:21.555Z"
   },
   {
    "duration": 3,
    "start_time": "2022-05-20T12:32:25.224Z"
   },
   {
    "duration": 10,
    "start_time": "2022-05-20T12:32:25.229Z"
   },
   {
    "duration": 5,
    "start_time": "2022-05-20T12:32:51.955Z"
   },
   {
    "duration": 5,
    "start_time": "2022-05-20T12:33:01.876Z"
   },
   {
    "duration": 6,
    "start_time": "2022-05-20T12:33:18.452Z"
   },
   {
    "duration": 5,
    "start_time": "2022-05-20T12:33:31.981Z"
   },
   {
    "duration": 4,
    "start_time": "2022-05-20T12:34:53.903Z"
   },
   {
    "duration": 6,
    "start_time": "2022-05-20T12:34:59.707Z"
   },
   {
    "duration": 5,
    "start_time": "2022-05-20T12:35:15.666Z"
   },
   {
    "duration": 3,
    "start_time": "2022-05-20T12:36:08.331Z"
   },
   {
    "duration": 5,
    "start_time": "2022-05-20T12:36:11.644Z"
   },
   {
    "duration": 5,
    "start_time": "2022-05-20T12:36:16.676Z"
   },
   {
    "duration": 5,
    "start_time": "2022-05-20T12:38:48.811Z"
   },
   {
    "duration": 3,
    "start_time": "2022-05-20T12:38:56.177Z"
   },
   {
    "duration": 5,
    "start_time": "2022-05-20T12:39:04.648Z"
   },
   {
    "duration": 4,
    "start_time": "2022-05-20T12:39:07.985Z"
   },
   {
    "duration": 6,
    "start_time": "2022-05-20T12:39:20.743Z"
   },
   {
    "duration": 4,
    "start_time": "2022-05-20T12:40:31.312Z"
   },
   {
    "duration": 4,
    "start_time": "2022-05-20T12:40:37.832Z"
   },
   {
    "duration": 5,
    "start_time": "2022-05-20T12:40:40.412Z"
   },
   {
    "duration": 5,
    "start_time": "2022-05-20T12:40:55.575Z"
   },
   {
    "duration": 10,
    "start_time": "2022-05-20T12:40:56.800Z"
   },
   {
    "duration": 21,
    "start_time": "2022-05-20T12:40:59.736Z"
   },
   {
    "duration": 3,
    "start_time": "2022-05-20T12:41:12.928Z"
   },
   {
    "duration": 4,
    "start_time": "2022-05-20T12:41:13.942Z"
   },
   {
    "duration": 4,
    "start_time": "2022-05-20T12:41:18.157Z"
   },
   {
    "duration": 27,
    "start_time": "2022-05-20T12:41:27.488Z"
   },
   {
    "duration": 3,
    "start_time": "2022-05-20T12:41:31.318Z"
   },
   {
    "duration": 3,
    "start_time": "2022-05-20T12:41:40.990Z"
   },
   {
    "duration": 4,
    "start_time": "2022-05-20T12:41:41.729Z"
   },
   {
    "duration": 6100,
    "start_time": "2022-05-20T12:42:46.238Z"
   },
   {
    "duration": 725,
    "start_time": "2022-05-20T12:42:56.143Z"
   },
   {
    "duration": 5,
    "start_time": "2022-05-20T12:43:02.266Z"
   },
   {
    "duration": 4,
    "start_time": "2022-05-20T12:43:06.782Z"
   },
   {
    "duration": 4,
    "start_time": "2022-05-20T12:43:12.551Z"
   },
   {
    "duration": 4,
    "start_time": "2022-05-20T12:45:23.165Z"
   },
   {
    "duration": 4,
    "start_time": "2022-05-20T12:45:28.077Z"
   },
   {
    "duration": 10,
    "start_time": "2022-05-20T12:45:32.685Z"
   },
   {
    "duration": 4,
    "start_time": "2022-05-20T12:45:37.263Z"
   },
   {
    "duration": 4,
    "start_time": "2022-05-20T12:45:42.313Z"
   },
   {
    "duration": 4,
    "start_time": "2022-05-20T12:45:45.429Z"
   },
   {
    "duration": 4,
    "start_time": "2022-05-20T12:46:08.533Z"
   },
   {
    "duration": 9,
    "start_time": "2022-05-20T12:46:52.749Z"
   },
   {
    "duration": 10,
    "start_time": "2022-05-20T12:47:01.357Z"
   },
   {
    "duration": 2,
    "start_time": "2022-05-20T12:48:16.228Z"
   },
   {
    "duration": 5,
    "start_time": "2022-05-20T12:48:19.679Z"
   },
   {
    "duration": 11,
    "start_time": "2022-05-20T12:48:24.828Z"
   },
   {
    "duration": 3,
    "start_time": "2022-05-20T12:49:17.780Z"
   },
   {
    "duration": 5,
    "start_time": "2022-05-20T12:50:02.617Z"
   },
   {
    "duration": 150,
    "start_time": "2022-05-20T12:52:23.690Z"
   },
   {
    "duration": 25,
    "start_time": "2022-05-20T12:52:32.636Z"
   },
   {
    "duration": 5,
    "start_time": "2022-05-20T12:52:50.633Z"
   },
   {
    "duration": 4,
    "start_time": "2022-05-20T12:52:54.021Z"
   },
   {
    "duration": 4,
    "start_time": "2022-05-20T12:53:13.131Z"
   },
   {
    "duration": 14,
    "start_time": "2022-05-20T12:53:22.516Z"
   },
   {
    "duration": 5,
    "start_time": "2022-05-20T12:53:32.924Z"
   },
   {
    "duration": 12,
    "start_time": "2022-05-20T12:54:04.124Z"
   },
   {
    "duration": 4,
    "start_time": "2022-05-20T12:54:26.451Z"
   },
   {
    "duration": 3,
    "start_time": "2022-05-20T12:54:35.978Z"
   },
   {
    "duration": 4,
    "start_time": "2022-05-20T12:54:40.061Z"
   },
   {
    "duration": 3,
    "start_time": "2022-05-20T12:54:43.770Z"
   },
   {
    "duration": 4,
    "start_time": "2022-05-20T12:54:53.207Z"
   },
   {
    "duration": 4,
    "start_time": "2022-05-20T12:55:05.929Z"
   },
   {
    "duration": 171,
    "start_time": "2022-05-20T12:56:26.125Z"
   },
   {
    "duration": 194,
    "start_time": "2022-05-20T12:56:44.148Z"
   },
   {
    "duration": 159,
    "start_time": "2022-05-20T12:56:49.570Z"
   },
   {
    "duration": 204,
    "start_time": "2022-05-20T12:56:55.714Z"
   },
   {
    "duration": 157,
    "start_time": "2022-05-20T12:57:30.324Z"
   },
   {
    "duration": 188,
    "start_time": "2022-05-20T12:57:40.120Z"
   },
   {
    "duration": 235,
    "start_time": "2022-05-20T12:57:44.649Z"
   },
   {
    "duration": 226,
    "start_time": "2022-05-20T12:57:56.386Z"
   },
   {
    "duration": 211,
    "start_time": "2022-05-20T12:58:03.617Z"
   },
   {
    "duration": 169,
    "start_time": "2022-05-20T12:58:21.240Z"
   },
   {
    "duration": 197,
    "start_time": "2022-05-20T12:58:28.578Z"
   },
   {
    "duration": 3714,
    "start_time": "2022-05-20T12:59:13.316Z"
   },
   {
    "duration": 751,
    "start_time": "2022-05-20T12:59:17.032Z"
   },
   {
    "duration": 5,
    "start_time": "2022-05-20T12:59:25.177Z"
   },
   {
    "duration": 1812,
    "start_time": "2022-05-24T06:19:46.588Z"
   },
   {
    "duration": 3752,
    "start_time": "2022-05-24T06:19:48.402Z"
   },
   {
    "duration": 101,
    "start_time": "2022-05-24T06:19:52.155Z"
   },
   {
    "duration": 3,
    "start_time": "2022-05-24T06:19:52.258Z"
   },
   {
    "duration": 2044,
    "start_time": "2022-05-24T06:19:52.262Z"
   },
   {
    "duration": 31735,
    "start_time": "2022-05-24T06:19:54.307Z"
   },
   {
    "duration": 6285,
    "start_time": "2022-05-24T06:20:26.044Z"
   },
   {
    "duration": 163,
    "start_time": "2022-05-24T06:20:32.331Z"
   },
   {
    "duration": 60,
    "start_time": "2022-05-24T06:20:32.496Z"
   },
   {
    "duration": 145,
    "start_time": "2022-05-24T06:20:32.558Z"
   },
   {
    "duration": 95,
    "start_time": "2022-05-24T06:56:04.192Z"
   },
   {
    "duration": 1711,
    "start_time": "2022-05-24T06:56:40.661Z"
   },
   {
    "duration": 3494,
    "start_time": "2022-05-24T06:56:42.374Z"
   },
   {
    "duration": 98,
    "start_time": "2022-05-24T06:56:45.870Z"
   },
   {
    "duration": 3,
    "start_time": "2022-05-24T06:56:45.970Z"
   },
   {
    "duration": 2229,
    "start_time": "2022-05-24T06:56:45.976Z"
   },
   {
    "duration": 33928,
    "start_time": "2022-05-24T06:56:48.207Z"
   },
   {
    "duration": 6703,
    "start_time": "2022-05-24T06:57:22.137Z"
   },
   {
    "duration": 109,
    "start_time": "2022-05-24T06:57:28.842Z"
   },
   {
    "duration": 160,
    "start_time": "2022-05-24T06:59:08.404Z"
   },
   {
    "duration": 197,
    "start_time": "2022-05-24T06:59:39.618Z"
   },
   {
    "duration": 5,
    "start_time": "2022-05-24T06:59:54.986Z"
   },
   {
    "duration": 5,
    "start_time": "2022-05-24T07:00:17.380Z"
   },
   {
    "duration": 5,
    "start_time": "2022-05-24T08:17:18.395Z"
   },
   {
    "duration": 181,
    "start_time": "2022-05-24T08:17:43.037Z"
   },
   {
    "duration": 210,
    "start_time": "2022-05-24T08:17:47.099Z"
   },
   {
    "duration": 10,
    "start_time": "2022-05-24T08:29:39.438Z"
   },
   {
    "duration": 51,
    "start_time": "2022-05-24T08:29:45.144Z"
   },
   {
    "duration": 5,
    "start_time": "2022-05-24T08:29:45.198Z"
   },
   {
    "duration": 4,
    "start_time": "2022-05-24T08:30:03.860Z"
   },
   {
    "duration": 1429,
    "start_time": "2022-05-24T08:34:43.756Z"
   },
   {
    "duration": 4514,
    "start_time": "2022-05-24T08:35:40.875Z"
   },
   {
    "duration": 4,
    "start_time": "2022-05-24T09:59:31.529Z"
   },
   {
    "duration": 3571,
    "start_time": "2022-05-24T09:59:31.535Z"
   },
   {
    "duration": 12,
    "start_time": "2022-05-24T09:59:35.108Z"
   },
   {
    "duration": 37,
    "start_time": "2022-05-24T09:59:35.123Z"
   },
   {
    "duration": 2287,
    "start_time": "2022-05-24T09:59:35.164Z"
   },
   {
    "duration": 31540,
    "start_time": "2022-05-24T09:59:37.453Z"
   },
   {
    "duration": 53,
    "start_time": "2022-05-24T10:00:08.995Z"
   },
   {
    "duration": 6687,
    "start_time": "2022-05-24T10:00:09.050Z"
   }
  ],
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Содержание",
   "title_sidebar": "Содержание",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "302.391px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
