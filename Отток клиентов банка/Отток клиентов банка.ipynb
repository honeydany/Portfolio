{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Отток клиентов банка"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Содержание<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Введение\" data-toc-modified-id=\"Введение-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Введение</a></span></li><li><span><a href=\"#Подготовка-данных\" data-toc-modified-id=\"Подготовка-данных-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Подготовка данных</a></span><ul class=\"toc-item\"><li><span><a href=\"#Загрузка\" data-toc-modified-id=\"Загрузка-2.1\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span>Загрузка</a></span></li><li><span><a href=\"#Подготовка\" data-toc-modified-id=\"Подготовка-2.2\"><span class=\"toc-item-num\">2.2&nbsp;&nbsp;</span>Подготовка</a></span></li><li><span><a href=\"#Вывод\" data-toc-modified-id=\"Вывод-2.3\"><span class=\"toc-item-num\">2.3&nbsp;&nbsp;</span>Вывод</a></span></li></ul></li><li><span><a href=\"#Исследование-задачи\" data-toc-modified-id=\"Исследование-задачи-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Исследование задачи</a></span><ul class=\"toc-item\"><li><span><a href=\"#Исследование-баланса-классов\" data-toc-modified-id=\"Исследование-баланса-классов-3.1\"><span class=\"toc-item-num\">3.1&nbsp;&nbsp;</span>Исследование баланса классов</a></span></li><li><span><a href=\"#Обучение-модели-без-учёта-дисбаланса\" data-toc-modified-id=\"Обучение-модели-без-учёта-дисбаланса-3.2\"><span class=\"toc-item-num\">3.2&nbsp;&nbsp;</span>Обучение модели без учёта дисбаланса</a></span><ul class=\"toc-item\"><li><span><a href=\"#Обучение-модели-дерева-решений\" data-toc-modified-id=\"Обучение-модели-дерева-решений-3.2.1\"><span class=\"toc-item-num\">3.2.1&nbsp;&nbsp;</span>Обучение модели дерева решений</a></span></li><li><span><a href=\"#Обучение-модели-случайного-леса\" data-toc-modified-id=\"Обучение-модели-случайного-леса-3.2.2\"><span class=\"toc-item-num\">3.2.2&nbsp;&nbsp;</span>Обучение модели случайного леса</a></span></li><li><span><a href=\"#Обучение-модели-логистической-регрессии\" data-toc-modified-id=\"Обучение-модели-логистической-регрессии-3.2.3\"><span class=\"toc-item-num\">3.2.3&nbsp;&nbsp;</span>Обучение модели логистической регрессии</a></span></li><li><span><a href=\"#Вывод\" data-toc-modified-id=\"Вывод-3.2.4\"><span class=\"toc-item-num\">3.2.4&nbsp;&nbsp;</span>Вывод</a></span></li></ul></li></ul></li><li><span><a href=\"#Борьба-с-дисбалансом\" data-toc-modified-id=\"Борьба-с-дисбалансом-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Борьба с дисбалансом</a></span><ul class=\"toc-item\"><li><span><a href=\"#Взвешивание-классов\" data-toc-modified-id=\"Взвешивание-классов-4.1\"><span class=\"toc-item-num\">4.1&nbsp;&nbsp;</span>Взвешивание классов</a></span><ul class=\"toc-item\"><li><span><a href=\"#Обучение-модели-дерева-решений-с-взвешиванием-классов\" data-toc-modified-id=\"Обучение-модели-дерева-решений-с-взвешиванием-классов-4.1.1\"><span class=\"toc-item-num\">4.1.1&nbsp;&nbsp;</span>Обучение модели дерева решений с взвешиванием классов</a></span></li><li><span><a href=\"#Обучение-модели-случайного-леса-с-взвешиванием-классов\" data-toc-modified-id=\"Обучение-модели-случайного-леса-с-взвешиванием-классов-4.1.2\"><span class=\"toc-item-num\">4.1.2&nbsp;&nbsp;</span>Обучение модели случайного леса с взвешиванием классов</a></span></li><li><span><a href=\"#Обучение-модели-логистической-регрессии-с-взвешиванием-классов\" data-toc-modified-id=\"Обучение-модели-логистической-регрессии-с-взвешиванием-классов-4.1.3\"><span class=\"toc-item-num\">4.1.3&nbsp;&nbsp;</span>Обучение модели логистической регрессии с взвешиванием классов</a></span></li><li><span><a href=\"#Вывод\" data-toc-modified-id=\"Вывод-4.1.4\"><span class=\"toc-item-num\">4.1.4&nbsp;&nbsp;</span>Вывод</a></span></li></ul></li><li><span><a href=\"#Изменение-порога-логистической-регрессии\" data-toc-modified-id=\"Изменение-порога-логистической-регрессии-4.2\"><span class=\"toc-item-num\">4.2&nbsp;&nbsp;</span>Изменение порога логистической регрессии</a></span><ul class=\"toc-item\"><li><span><a href=\"#Вывод\" data-toc-modified-id=\"Вывод-4.2.1\"><span class=\"toc-item-num\">4.2.1&nbsp;&nbsp;</span>Вывод</a></span></li></ul></li><li><span><a href=\"#Увеличение-выборки\" data-toc-modified-id=\"Увеличение-выборки-4.3\"><span class=\"toc-item-num\">4.3&nbsp;&nbsp;</span>Увеличение выборки</a></span><ul class=\"toc-item\"><li><span><a href=\"#Обучение-модели-дерева-решений-на-увеличенной-выборке\" data-toc-modified-id=\"Обучение-модели-дерева-решений-на-увеличенной-выборке-4.3.1\"><span class=\"toc-item-num\">4.3.1&nbsp;&nbsp;</span>Обучение модели дерева решений на увеличенной выборке</a></span></li><li><span><a href=\"#Обучение-модели-случайного-леса-на-увеличенной-выборке\" data-toc-modified-id=\"Обучение-модели-случайного-леса-на-увеличенной-выборке-4.3.2\"><span class=\"toc-item-num\">4.3.2&nbsp;&nbsp;</span>Обучение модели случайного леса на увеличенной выборке</a></span></li><li><span><a href=\"#Обучение-модели-логистической-регрессии-на-увеличенной-выборке\" data-toc-modified-id=\"Обучение-модели-логистической-регрессии-на-увеличенной-выборке-4.3.3\"><span class=\"toc-item-num\">4.3.3&nbsp;&nbsp;</span>Обучение модели логистической регрессии на увеличенной выборке</a></span></li><li><span><a href=\"#Вывод\" data-toc-modified-id=\"Вывод-4.3.4\"><span class=\"toc-item-num\">4.3.4&nbsp;&nbsp;</span>Вывод</a></span></li></ul></li><li><span><a href=\"#Уменьшение-выборки\" data-toc-modified-id=\"Уменьшение-выборки-4.4\"><span class=\"toc-item-num\">4.4&nbsp;&nbsp;</span>Уменьшение выборки</a></span><ul class=\"toc-item\"><li><span><a href=\"#Обучение-модели-дерева-решений-на-уменьшенной-выборке\" data-toc-modified-id=\"Обучение-модели-дерева-решений-на-уменьшенной-выборке-4.4.1\"><span class=\"toc-item-num\">4.4.1&nbsp;&nbsp;</span>Обучение модели дерева решений на уменьшенной выборке</a></span></li><li><span><a href=\"#Обучение-модели-случайного-леса-на-уменьшенной-выборке\" data-toc-modified-id=\"Обучение-модели-случайного-леса-на-уменьшенной-выборке-4.4.2\"><span class=\"toc-item-num\">4.4.2&nbsp;&nbsp;</span>Обучение модели случайного леса на уменьшенной выборке</a></span></li><li><span><a href=\"#Обучение-модели-логистической-регрессии-на-уменьшенной-выборке\" data-toc-modified-id=\"Обучение-модели-логистической-регрессии-на-уменьшенной-выборке-4.4.3\"><span class=\"toc-item-num\">4.4.3&nbsp;&nbsp;</span>Обучение модели логистической регрессии на уменьшенной выборке</a></span></li><li><span><a href=\"#Вывод\" data-toc-modified-id=\"Вывод-4.4.4\"><span class=\"toc-item-num\">4.4.4&nbsp;&nbsp;</span>Вывод</a></span></li></ul></li><li><span><a href=\"#Масштабирование-признаков\" data-toc-modified-id=\"Масштабирование-признаков-4.5\"><span class=\"toc-item-num\">4.5&nbsp;&nbsp;</span>Масштабирование признаков</a></span><ul class=\"toc-item\"><li><span><a href=\"#Обучение-модели-дерева-решений-на-масштабированной-выборке\" data-toc-modified-id=\"Обучение-модели-дерева-решений-на-масштабированной-выборке-4.5.1\"><span class=\"toc-item-num\">4.5.1&nbsp;&nbsp;</span>Обучение модели дерева решений на масштабированной выборке</a></span></li><li><span><a href=\"#Обучение-модели-случайного-леса-на-масштабированной-выборке\" data-toc-modified-id=\"Обучение-модели-случайного-леса-на-масштабированной-выборке-4.5.2\"><span class=\"toc-item-num\">4.5.2&nbsp;&nbsp;</span>Обучение модели случайного леса на масштабированной выборке</a></span></li><li><span><a href=\"#Обучение-модели-логистической-регрессии-на-масштабированной-выборке\" data-toc-modified-id=\"Обучение-модели-логистической-регрессии-на-масштабированной-выборке-4.5.3\"><span class=\"toc-item-num\">4.5.3&nbsp;&nbsp;</span>Обучение модели логистической регрессии на масштабированной выборке</a></span></li><li><span><a href=\"#Вывод\" data-toc-modified-id=\"Вывод-4.5.4\"><span class=\"toc-item-num\">4.5.4&nbsp;&nbsp;</span>Вывод</a></span></li></ul></li><li><span><a href=\"#Общий-вывод-по-п.4\" data-toc-modified-id=\"Общий-вывод-по-п.4-4.6\"><span class=\"toc-item-num\">4.6&nbsp;&nbsp;</span>Общий вывод по п.4</a></span></li></ul></li><li><span><a href=\"#Тестирование-модели\" data-toc-modified-id=\"Тестирование-модели-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>Тестирование модели</a></span></li><li><span><a href=\"#Итоги-исследования\" data-toc-modified-id=\"Итоги-исследования-6\"><span class=\"toc-item-num\">6&nbsp;&nbsp;</span>Итоги исследования</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Введение"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Описание**\n",
    "\n",
    "Из «Бета-Банка» стали уходить клиенты. Каждый месяц. Немного, но заметно. Банковские маркетологи посчитали: сохранять текущих клиентов дешевле, чем привлекать новых.\n",
    "\n",
    "**Исходные данные** \n",
    "\n",
    "Вам предоставлены исторические данные о поведении клиентов и расторжении договоров с банком.\n",
    "\n",
    "Данные находятся в файле `/datasets/Churn.csv` (англ. «отток клиентов»).\n",
    "\n",
    "**Описание данных:**\n",
    "\n",
    "1. Признаки:\n",
    "\n",
    "* `RowNumber` — индекс строки в данных\n",
    "* `CustomerId` — уникальный идентификатор клиента\n",
    "* `Surname` — фамилия\n",
    "* `CreditScore` — кредитный рейтинг\n",
    "* `Geography` — страна проживания\n",
    "* `Gender` — пол\n",
    "* `Age` — возраст\n",
    "* `Tenure` — сколько лет человек является клиентом банка\n",
    "* `Balance` — баланс на счёте\n",
    "* `NumOfProducts` — количество продуктов банка, используемых клиентом\n",
    "* `HasCrCard` — наличие кредитной карты\n",
    "* `IsActiveMember` — активность клиента\n",
    "* `EstimatedSalary` — предполагаемая зарплата\n",
    "\n",
    "2. Целевой признак\n",
    "\n",
    "* `Exited` — факт ухода клиента\n",
    "\n",
    "**Цель** - спрогнозировать, уйдёт клиент из банка в ближайшее время или нет. \n",
    "\n",
    "Для достижения поставленной цели необходимо:\n",
    "\n",
    "* Постройте модель с предельно большим значением *F1*-меры. Чтобы сдать проект успешно, нужно довести метрику до 0.59. Проверьте *F1*-меру на тестовой выборке самостоятельно.\n",
    "* Дополнительно измеряйте *AUC-ROC*, сравнивайте её значение с *F1*-мерой.\n",
    "\n",
    "**Задачи:**\n",
    "\n",
    "1. Подготовка данных: \n",
    "    * загрузите и подготовьте данные: наличие дубликатов, формат заголовков\n",
    "2. Исследование задачи:\n",
    "    * исследуйте баланс классов\n",
    "    * обучите модель без учёта дисбаланса\n",
    "3. Борьба с дисбалансом:\n",
    "    * улучшите качество модели, учитывая дисбаланс классов\n",
    "    * обучите разные модели и найдите лучшую\n",
    "4. Финальное тестирование модели;\n",
    "5. Подведение итогов исследования.\n",
    "\n",
    "Источник данных: [https://www.kaggle.com/barelydedicated/bank-customer-churn-modeling](https://www.kaggle.com/barelydedicated/bank-customer-churn-modeling)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Подготовка данных"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Загрузка"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# импорт бибилиотек и необходимых модулей\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import f1_score, roc_auc_score, roc_curve\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# pyplot\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RowNumber</th>\n",
       "      <th>CustomerId</th>\n",
       "      <th>Surname</th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Geography</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>15634602</td>\n",
       "      <td>Hargrave</td>\n",
       "      <td>619</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101348.88</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>15647311</td>\n",
       "      <td>Hill</td>\n",
       "      <td>608</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>41</td>\n",
       "      <td>1.0</td>\n",
       "      <td>83807.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112542.58</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>15619304</td>\n",
       "      <td>Onio</td>\n",
       "      <td>502</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>8.0</td>\n",
       "      <td>159660.80</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113931.57</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>15701354</td>\n",
       "      <td>Boni</td>\n",
       "      <td>699</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>39</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93826.63</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>15737888</td>\n",
       "      <td>Mitchell</td>\n",
       "      <td>850</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>43</td>\n",
       "      <td>2.0</td>\n",
       "      <td>125510.82</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>79084.10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9995</td>\n",
       "      <td>9996</td>\n",
       "      <td>15606229</td>\n",
       "      <td>Obijiaku</td>\n",
       "      <td>771</td>\n",
       "      <td>France</td>\n",
       "      <td>Male</td>\n",
       "      <td>39</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>96270.64</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9996</td>\n",
       "      <td>9997</td>\n",
       "      <td>15569892</td>\n",
       "      <td>Johnstone</td>\n",
       "      <td>516</td>\n",
       "      <td>France</td>\n",
       "      <td>Male</td>\n",
       "      <td>35</td>\n",
       "      <td>10.0</td>\n",
       "      <td>57369.61</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101699.77</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9997</td>\n",
       "      <td>9998</td>\n",
       "      <td>15584532</td>\n",
       "      <td>Liu</td>\n",
       "      <td>709</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>36</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>42085.58</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9998</td>\n",
       "      <td>9999</td>\n",
       "      <td>15682355</td>\n",
       "      <td>Sabbatini</td>\n",
       "      <td>772</td>\n",
       "      <td>Germany</td>\n",
       "      <td>Male</td>\n",
       "      <td>42</td>\n",
       "      <td>3.0</td>\n",
       "      <td>75075.31</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>92888.52</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9999</td>\n",
       "      <td>10000</td>\n",
       "      <td>15628319</td>\n",
       "      <td>Walker</td>\n",
       "      <td>792</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>28</td>\n",
       "      <td>NaN</td>\n",
       "      <td>130142.79</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>38190.78</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      RowNumber  CustomerId    Surname  CreditScore Geography  Gender  Age  \\\n",
       "0             1    15634602   Hargrave          619    France  Female   42   \n",
       "1             2    15647311       Hill          608     Spain  Female   41   \n",
       "2             3    15619304       Onio          502    France  Female   42   \n",
       "3             4    15701354       Boni          699    France  Female   39   \n",
       "4             5    15737888   Mitchell          850     Spain  Female   43   \n",
       "...         ...         ...        ...          ...       ...     ...  ...   \n",
       "9995       9996    15606229   Obijiaku          771    France    Male   39   \n",
       "9996       9997    15569892  Johnstone          516    France    Male   35   \n",
       "9997       9998    15584532        Liu          709    France  Female   36   \n",
       "9998       9999    15682355  Sabbatini          772   Germany    Male   42   \n",
       "9999      10000    15628319     Walker          792    France  Female   28   \n",
       "\n",
       "      Tenure    Balance  NumOfProducts  HasCrCard  IsActiveMember  \\\n",
       "0        2.0       0.00              1          1               1   \n",
       "1        1.0   83807.86              1          0               1   \n",
       "2        8.0  159660.80              3          1               0   \n",
       "3        1.0       0.00              2          0               0   \n",
       "4        2.0  125510.82              1          1               1   \n",
       "...      ...        ...            ...        ...             ...   \n",
       "9995     5.0       0.00              2          1               0   \n",
       "9996    10.0   57369.61              1          1               1   \n",
       "9997     7.0       0.00              1          0               1   \n",
       "9998     3.0   75075.31              2          1               0   \n",
       "9999     NaN  130142.79              1          1               0   \n",
       "\n",
       "      EstimatedSalary  Exited  \n",
       "0           101348.88       1  \n",
       "1           112542.58       0  \n",
       "2           113931.57       1  \n",
       "3            93826.63       0  \n",
       "4            79084.10       0  \n",
       "...               ...     ...  \n",
       "9995         96270.64       0  \n",
       "9996        101699.77       0  \n",
       "9997         42085.58       1  \n",
       "9998         92888.52       1  \n",
       "9999         38190.78       0  \n",
       "\n",
       "[10000 rows x 14 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10000 entries, 0 to 9999\n",
      "Data columns (total 14 columns):\n",
      "RowNumber          10000 non-null int64\n",
      "CustomerId         10000 non-null int64\n",
      "Surname            10000 non-null object\n",
      "CreditScore        10000 non-null int64\n",
      "Geography          10000 non-null object\n",
      "Gender             10000 non-null object\n",
      "Age                10000 non-null int64\n",
      "Tenure             9091 non-null float64\n",
      "Balance            10000 non-null float64\n",
      "NumOfProducts      10000 non-null int64\n",
      "HasCrCard          10000 non-null int64\n",
      "IsActiveMember     10000 non-null int64\n",
      "EstimatedSalary    10000 non-null float64\n",
      "Exited             10000 non-null int64\n",
      "dtypes: float64(3), int64(8), object(3)\n",
      "memory usage: 1.1+ MB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RowNumber</th>\n",
       "      <th>CustomerId</th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>count</td>\n",
       "      <td>10000.00000</td>\n",
       "      <td>1.000000e+04</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>9091.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.00000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>mean</td>\n",
       "      <td>5000.50000</td>\n",
       "      <td>1.569094e+07</td>\n",
       "      <td>650.528800</td>\n",
       "      <td>38.921800</td>\n",
       "      <td>4.997690</td>\n",
       "      <td>76485.889288</td>\n",
       "      <td>1.530200</td>\n",
       "      <td>0.70550</td>\n",
       "      <td>0.515100</td>\n",
       "      <td>100090.239881</td>\n",
       "      <td>0.203700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>std</td>\n",
       "      <td>2886.89568</td>\n",
       "      <td>7.193619e+04</td>\n",
       "      <td>96.653299</td>\n",
       "      <td>10.487806</td>\n",
       "      <td>2.894723</td>\n",
       "      <td>62397.405202</td>\n",
       "      <td>0.581654</td>\n",
       "      <td>0.45584</td>\n",
       "      <td>0.499797</td>\n",
       "      <td>57510.492818</td>\n",
       "      <td>0.402769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>min</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.556570e+07</td>\n",
       "      <td>350.000000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>11.580000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25%</td>\n",
       "      <td>2500.75000</td>\n",
       "      <td>1.562853e+07</td>\n",
       "      <td>584.000000</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>51002.110000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50%</td>\n",
       "      <td>5000.50000</td>\n",
       "      <td>1.569074e+07</td>\n",
       "      <td>652.000000</td>\n",
       "      <td>37.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>97198.540000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>100193.915000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75%</td>\n",
       "      <td>7500.25000</td>\n",
       "      <td>1.575323e+07</td>\n",
       "      <td>718.000000</td>\n",
       "      <td>44.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>127644.240000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>149388.247500</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>max</td>\n",
       "      <td>10000.00000</td>\n",
       "      <td>1.581569e+07</td>\n",
       "      <td>850.000000</td>\n",
       "      <td>92.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>250898.090000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>199992.480000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         RowNumber    CustomerId   CreditScore           Age       Tenure  \\\n",
       "count  10000.00000  1.000000e+04  10000.000000  10000.000000  9091.000000   \n",
       "mean    5000.50000  1.569094e+07    650.528800     38.921800     4.997690   \n",
       "std     2886.89568  7.193619e+04     96.653299     10.487806     2.894723   \n",
       "min        1.00000  1.556570e+07    350.000000     18.000000     0.000000   \n",
       "25%     2500.75000  1.562853e+07    584.000000     32.000000     2.000000   \n",
       "50%     5000.50000  1.569074e+07    652.000000     37.000000     5.000000   \n",
       "75%     7500.25000  1.575323e+07    718.000000     44.000000     7.000000   \n",
       "max    10000.00000  1.581569e+07    850.000000     92.000000    10.000000   \n",
       "\n",
       "             Balance  NumOfProducts    HasCrCard  IsActiveMember  \\\n",
       "count   10000.000000   10000.000000  10000.00000    10000.000000   \n",
       "mean    76485.889288       1.530200      0.70550        0.515100   \n",
       "std     62397.405202       0.581654      0.45584        0.499797   \n",
       "min         0.000000       1.000000      0.00000        0.000000   \n",
       "25%         0.000000       1.000000      0.00000        0.000000   \n",
       "50%     97198.540000       1.000000      1.00000        1.000000   \n",
       "75%    127644.240000       2.000000      1.00000        1.000000   \n",
       "max    250898.090000       4.000000      1.00000        1.000000   \n",
       "\n",
       "       EstimatedSalary        Exited  \n",
       "count     10000.000000  10000.000000  \n",
       "mean     100090.239881      0.203700  \n",
       "std       57510.492818      0.402769  \n",
       "min          11.580000      0.000000  \n",
       "25%       51002.110000      0.000000  \n",
       "50%      100193.915000      0.000000  \n",
       "75%      149388.247500      0.000000  \n",
       "max      199992.480000      1.000000  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('/datasets/Churn.csv') #\n",
    "\n",
    "# выведем первые и последние 5 строк df, общую информацию о столбцах\n",
    "display(df)\n",
    "df.info()\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Дубликатов в таблице -  0\n"
     ]
    }
   ],
   "source": [
    "print('Дубликатов в таблице - ', df.duplicated().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Вывод:**\n",
    "* тип данных в столбцах соответствует содержащейся в них информации;\n",
    "* столбец `Tenure` — сколько лет человек является клиентом банка — имеет пропуски в данных, поэтому требуется более глубокий анализ;\n",
    "* столбец `RowNumber` являтся лишним, т.к. дублирует индекс таблицы;\n",
    "* столбец `Surname` можно удалить, т.к. он не повлияет на разработку модели, а при необходимости его можно восстановить с помощью `CustomerId`;\n",
    "* присутствует существенный разброс в данных, например в столбцах `Age`, `Tenure` и т.д.;\n",
    "* дубликаты в таблице отсутствуют;\n",
    "* название заголовков в \"верблюжем\" регистре;\n",
    "* в столбце `Gender` содержатся категориальные признаки о поле человека (Male, female),а в `Geography` содержатся данные о стране проживания клиента. С помощью `техник OHE` преобразуем (закодируем) их в численные;\n",
    "\n",
    "**Предлагается:**\n",
    "* столбцы `RowNumber`,`Surname` удалить;\n",
    "* заголовки столбцов привести к \"змеиному регистру\";\n",
    "* изучить данные в столбце `Tenure`, выдвинуть предположения о причине пропусков, попытаться их заполнить;\n",
    "* данные столбцов `Gender` и `Geography` закодировать с помощью техники OHE (прямого кодирования)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Подготовка"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# удаление столбца `RowNumber`,`Surname`\n",
    "df.drop(columns=['RowNumber', 'Surname'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customerid</th>\n",
       "      <th>creditscore</th>\n",
       "      <th>age</th>\n",
       "      <th>tenure</th>\n",
       "      <th>balance</th>\n",
       "      <th>numofproducts</th>\n",
       "      <th>hascrcard</th>\n",
       "      <th>isactivemember</th>\n",
       "      <th>estimatedsalary</th>\n",
       "      <th>exited</th>\n",
       "      <th>geography_germany</th>\n",
       "      <th>geography_spain</th>\n",
       "      <th>gender_male</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>15634602</td>\n",
       "      <td>619</td>\n",
       "      <td>42</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101348.88</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>15647311</td>\n",
       "      <td>608</td>\n",
       "      <td>41</td>\n",
       "      <td>1.0</td>\n",
       "      <td>83807.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112542.58</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>15619304</td>\n",
       "      <td>502</td>\n",
       "      <td>42</td>\n",
       "      <td>8.0</td>\n",
       "      <td>159660.80</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113931.57</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>15701354</td>\n",
       "      <td>699</td>\n",
       "      <td>39</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93826.63</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>15737888</td>\n",
       "      <td>850</td>\n",
       "      <td>43</td>\n",
       "      <td>2.0</td>\n",
       "      <td>125510.82</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>79084.10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   customerid  creditscore  age  tenure    balance  numofproducts  hascrcard  \\\n",
       "0    15634602          619   42     2.0       0.00              1          1   \n",
       "1    15647311          608   41     1.0   83807.86              1          0   \n",
       "2    15619304          502   42     8.0  159660.80              3          1   \n",
       "3    15701354          699   39     1.0       0.00              2          0   \n",
       "4    15737888          850   43     2.0  125510.82              1          1   \n",
       "\n",
       "   isactivemember  estimatedsalary  exited  geography_germany  \\\n",
       "0               1        101348.88       1                  0   \n",
       "1               1        112542.58       0                  0   \n",
       "2               0        113931.57       1                  0   \n",
       "3               0         93826.63       0                  0   \n",
       "4               1         79084.10       0                  0   \n",
       "\n",
       "   geography_spain  gender_male  \n",
       "0                0            0  \n",
       "1                1            0  \n",
       "2                0            0  \n",
       "3                0            0  \n",
       "4                1            0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# применение методики OHE к df\n",
    "# укажем параметр 'drop_first=True' при кодировании данных столбцов 'gender' и 'geography'\n",
    "# чтобы не угодит в дамми-ловушку\n",
    "df = pd.get_dummies(df,\n",
    "                    drop_first=True,dtype='int64')\n",
    "\n",
    "# приведем названия столбцов к нижнему регистру\n",
    "df.columns = df.columns.str.lower()\n",
    "\n",
    "# проверим\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* изучить данные в столбце `Tenure`, выдвинуть предположения о причине пропусков, попытаться их заполнить."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customerid</th>\n",
       "      <th>creditscore</th>\n",
       "      <th>age</th>\n",
       "      <th>tenure</th>\n",
       "      <th>balance</th>\n",
       "      <th>numofproducts</th>\n",
       "      <th>hascrcard</th>\n",
       "      <th>isactivemember</th>\n",
       "      <th>estimatedsalary</th>\n",
       "      <th>exited</th>\n",
       "      <th>geography_germany</th>\n",
       "      <th>geography_spain</th>\n",
       "      <th>gender_male</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>15589475</td>\n",
       "      <td>591</td>\n",
       "      <td>39</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>140469.38</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>48</td>\n",
       "      <td>15766205</td>\n",
       "      <td>550</td>\n",
       "      <td>38</td>\n",
       "      <td>NaN</td>\n",
       "      <td>103391.38</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>90878.13</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>51</td>\n",
       "      <td>15768193</td>\n",
       "      <td>585</td>\n",
       "      <td>36</td>\n",
       "      <td>NaN</td>\n",
       "      <td>146050.97</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>86424.57</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>53</td>\n",
       "      <td>15702298</td>\n",
       "      <td>655</td>\n",
       "      <td>41</td>\n",
       "      <td>NaN</td>\n",
       "      <td>125561.97</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>164040.94</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>15651280</td>\n",
       "      <td>742</td>\n",
       "      <td>35</td>\n",
       "      <td>NaN</td>\n",
       "      <td>136857.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>84509.57</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>82</td>\n",
       "      <td>15641732</td>\n",
       "      <td>543</td>\n",
       "      <td>36</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>26019.59</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>85</td>\n",
       "      <td>15805254</td>\n",
       "      <td>652</td>\n",
       "      <td>75</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>114675.75</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>94</td>\n",
       "      <td>15676966</td>\n",
       "      <td>730</td>\n",
       "      <td>42</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>85982.47</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>99</td>\n",
       "      <td>15633059</td>\n",
       "      <td>413</td>\n",
       "      <td>34</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6534.18</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>111</td>\n",
       "      <td>15665790</td>\n",
       "      <td>538</td>\n",
       "      <td>39</td>\n",
       "      <td>NaN</td>\n",
       "      <td>108055.10</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>27231.26</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     customerid  creditscore  age  tenure    balance  numofproducts  \\\n",
       "30     15589475          591   39     NaN       0.00              3   \n",
       "48     15766205          550   38     NaN  103391.38              1   \n",
       "51     15768193          585   36     NaN  146050.97              2   \n",
       "53     15702298          655   41     NaN  125561.97              1   \n",
       "60     15651280          742   35     NaN  136857.00              1   \n",
       "82     15641732          543   36     NaN       0.00              2   \n",
       "85     15805254          652   75     NaN       0.00              2   \n",
       "94     15676966          730   42     NaN       0.00              2   \n",
       "99     15633059          413   34     NaN       0.00              2   \n",
       "111    15665790          538   39     NaN  108055.10              2   \n",
       "\n",
       "     hascrcard  isactivemember  estimatedsalary  exited  geography_germany  \\\n",
       "30           1               0        140469.38       1                  0   \n",
       "48           0               1         90878.13       0                  1   \n",
       "51           0               0         86424.57       0                  1   \n",
       "53           0               0        164040.94       1                  1   \n",
       "60           0               0         84509.57       0                  1   \n",
       "82           0               0         26019.59       0                  0   \n",
       "85           1               1        114675.75       0                  0   \n",
       "94           0               1         85982.47       0                  0   \n",
       "99           0               0          6534.18       0                  0   \n",
       "111          1               0         27231.26       0                  1   \n",
       "\n",
       "     geography_spain  gender_male  \n",
       "30                 1            0  \n",
       "48                 0            1  \n",
       "51                 0            1  \n",
       "53                 0            1  \n",
       "60                 0            1  \n",
       "82                 0            0  \n",
       "85                 1            0  \n",
       "94                 1            1  \n",
       "99                 0            1  \n",
       "111                0            1  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Кол-во пропусков в таблице -  909\n",
      "Уникальные значения в стобце \"tenure\": [ 2.  1.  8.  7.  4.  6.  3. 10.  5.  9.  0. nan]\n"
     ]
    }
   ],
   "source": [
    "display(df[df['tenure'].isna()].head(10))\n",
    "print('Кол-во пропусков в таблице - ',df[df['tenure'].isna()]['customerid'].count())\n",
    "print('Уникальные значения в стобце \"tenure\":',df['tenure'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Возможно, пропуски возникли вследствие ошибки системы или владение продуктами банка менее года (недавно оформили какой-либо из продуктов). Достоверно установить причину возникновения пропусков не представляется возможным. Предлагаем заменить все пропуски на `медианное значение`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10000 entries, 0 to 9999\n",
      "Data columns (total 13 columns):\n",
      "customerid           10000 non-null int64\n",
      "creditscore          10000 non-null int64\n",
      "age                  10000 non-null int64\n",
      "tenure               10000 non-null float64\n",
      "balance              10000 non-null float64\n",
      "numofproducts        10000 non-null int64\n",
      "hascrcard            10000 non-null int64\n",
      "isactivemember       10000 non-null int64\n",
      "estimatedsalary      10000 non-null float64\n",
      "exited               10000 non-null int64\n",
      "geography_germany    10000 non-null int64\n",
      "geography_spain      10000 non-null int64\n",
      "gender_male          10000 non-null int64\n",
      "dtypes: float64(3), int64(10)\n",
      "memory usage: 1015.8 KB\n"
     ]
    }
   ],
   "source": [
    "# замена пропусков на медиану\n",
    "df['tenure'] = df['tenure'].transform(lambda x: x.fillna(x.median()))\n",
    "\n",
    "# проверим\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Вывод\n",
    "* столбец `RowNumber` удален;\n",
    "* заголовки столбцов приведены к \"змеиному регистру\";\n",
    "* пропуски в столбце `Tenure` заменены на `медианное значение столбца`;\n",
    "* данные столбцов `Gender` и `Geography` закодированы с помощью техники OHE (прямого кодирования)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Исследование задачи"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Исследование баланса классов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Целевых значений с классом \"0\" -  7963\n",
      "Целевых значений с классом \"1\" -  2037\n"
     ]
    }
   ],
   "source": [
    "# вычислим баланс классов\n",
    "zero_class = df['exited'].value_counts()[0]\n",
    "one_class = df['exited'].value_counts()[1]\n",
    "\n",
    "print('Целевых значений с классом \"0\" - ', zero_class)\n",
    "print('Целевых значений с классом \"1\" - ', one_class)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Наблюдается явный дисбаланс классов в сторону `0` значений (около 80%).\n",
    "\n",
    "### Обучение модели без учёта дисбаланса"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Доля обучающей выборки -  0.6\n",
      "Доля валидационной выборки -  0.2\n",
      "Доля тестовой выборки -  0.2\n"
     ]
    }
   ],
   "source": [
    "# разделим выборку на две части: признаки и целевой признак. \n",
    "# присвоим их переменным 'features', 'target' соответсвенно\n",
    "\n",
    "features = df.drop('exited', axis=1)\n",
    "target = df['exited']\n",
    "\n",
    "# разделим выборку на 3 части: обучающую, валидационную, тестовую в пропорции 3:1:1\n",
    "# таким образом на обучающую выборку придется 60% данных, валидационную и тестовую - по 20%\n",
    "# разделение проведем в 2 этапа:\n",
    "\n",
    "# 1 этап:\n",
    "features_train, features_valid, target_train, target_valid = train_test_split(features,\n",
    "                                                                              target,\n",
    "                                                                              test_size=0.4,\n",
    "                                                                              random_state=12345)\n",
    "\n",
    "# 2 этап:\n",
    "features_valid, features_test, target_valid, target_test = train_test_split(features_valid,\n",
    "                                                            target_valid,\n",
    "                                                            test_size=0.5,\n",
    "                                                            random_state=12345)\n",
    "# проверим соотношение выборок:\n",
    "print('Доля обучающей выборки - ', target_train.count()/10000)\n",
    "print('Доля валидационной выборки - ', target_valid.count()/10000)\n",
    "print('Доля тестовой выборки - ', target_test.count()/10000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Обучение модели дерева решений"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-метрика с дисбалансом классов модели дерева решений -  0.489\n",
      "AUC-ROC-метрика с дисбалансом классов модели дерева решений -  0.678\n"
     ]
    }
   ],
   "source": [
    "# создадим объект 'model' структуры данных DecisionTreeClassifier\n",
    "# зададим псевдослучайность random_state=12345\n",
    "model = DecisionTreeClassifier(random_state=12345)\n",
    "\n",
    "# обучим модель на обучающей выборке\n",
    "model.fit(features_train, target_train)\n",
    "\n",
    "# произведем предсказания на валидационной выборке\n",
    "predictions = model.predict(features_valid)\n",
    "\n",
    "# качество предсказаний на валидационной выборке\n",
    "# f1-метрика\n",
    "print('F1-метрика с дисбалансом классов модели дерева решений - ', np.round(f1_score(target_valid, predictions), 3))\n",
    "\n",
    "# roc_auc_score\n",
    "# для расчета метрики area under ROC-curve необходимо вычислить вероятности класса \"1\" \n",
    "probabilities_valid = model.predict_proba(features_valid)\n",
    "probabilities_one_valid = probabilities_valid[:, 1]\n",
    "\n",
    "auc_roc = roc_auc_score(target_valid, probabilities_one_valid)\n",
    "print('AUC-ROC-метрика с дисбалансом классов модели дерева решений - ', np.round(auc_roc, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Обучение модели случайного леса"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-метрика с дисбалансом классов модели случайного леса -  0.537\n",
      "AUC-ROC-метрика с дисбалансом классов модели случайного леса -  0.804\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "# создадим объект 'model' структуры данных RandomForestClassifier\n",
    "# зададим псевдослучайность random_state=12345\n",
    "model = RandomForestClassifier(random_state=12345)\n",
    "\n",
    "# обучим модель на обучающей выборке\n",
    "model.fit(features_train, target_train)\n",
    "\n",
    "# произведем предсказания на валидационной выборке\n",
    "predictions = model.predict(features_valid)\n",
    "\n",
    "# качество предсказаний на валидационной выборке\n",
    "# f1-метрика\n",
    "print('F1-метрика с дисбалансом классов модели случайного леса - ', np.round(f1_score(target_valid, predictions),3))\n",
    "\n",
    "# roc_auc_score\n",
    "# для расчета метрики area under ROC-curve необходимо вычислить вероятности класса \"1\" \n",
    "probabilities_valid = model.predict_proba(features_valid)\n",
    "probabilities_one_valid = probabilities_valid[:, 1]\n",
    "\n",
    "auc_roc = roc_auc_score(target_valid, probabilities_one_valid)\n",
    "print('AUC-ROC-метрика с дисбалансом классов модели случайного леса - ', np.round(auc_roc,3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Обучение модели логистической регрессии"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-метрика с дисбалансом классов модели логистической регрессии -  0.0\n",
      "AUC-ROC-метрика с дисбалансом классов модели логистической регрессии -  0.566\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "# создадим объект 'model' структуры данных LogisticRegression\n",
    "# зададим псевдослучайность random_state=12345\n",
    "model = LogisticRegression(random_state=12345, solver='liblinear')\n",
    "\n",
    "# обучим модель на обучающей выборке\n",
    "model.fit(features_train, target_train)\n",
    "\n",
    "# произведем предсказания на валидационной выборке\n",
    "predictions = model.predict(features_valid)\n",
    "\n",
    "# качество предсказаний на валидационной выборке\n",
    "# f1-метрика\n",
    "print('F1-метрика с дисбалансом классов модели логистической регрессии - ', np.round(f1_score(target_valid, predictions),3))\n",
    "\n",
    "# roc_auc_score\n",
    "# для расчета метрики area under ROC-curve необходимо вычислить вероятности класса \"1\" \n",
    "probabilities_valid = model.predict_proba(features_valid)\n",
    "probabilities_one_valid = probabilities_valid[:, 1]\n",
    "\n",
    "auc_roc = roc_auc_score(target_valid, probabilities_one_valid)\n",
    "print('AUC-ROC-метрика с дисбалансом классов модели логистической регрессии - ', np.round(auc_roc,3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Вывод "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Были обучены модели дерева решений, случайного леса, логистической регрессии;\n",
    "\n",
    "2. Рассчитаны метрики качества F1 и AUC-ROC для каждой модели:\n",
    "\n",
    "2.1 `F1-метрика с дисбалансом классов` для моделей:\n",
    "* дерева решений -  `0.489`\n",
    "* случайного леса -  `0.537`\n",
    "* логистической регрессии -  `0.0`\n",
    "\n",
    "2.2 `AUC-ROC-метрика с дисбалансом классов` для моделей:\n",
    "* дерева решений -  `0.678`\n",
    "* случайного леса -  `0.804`\n",
    "* логистической регрессии -  `0.566`\n",
    "\n",
    "Для модели логистической регрессиии F1-метрика выдала `0`, т.к. не смогла предсказать значения целевого признака вследствие сильного дисбаланса классов."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Борьба с дисбалансом"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* улучшите качество модели, учитывая дисбаланс классов\n",
    "* обучите разные модели и найдите лучшую\n",
    "\n",
    "Обучим модели из предыдущего пункта, учитывая дисбаланс классов с применением разных методик."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Взвешивание классов"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Обучение модели дерева решений с взвешиванием классов"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* стандартные гиперпараметры"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-метрика с взвешиванием классов модели дерева решений -  0.479\n",
      "AUC-ROC-метрика с взвешиванием классов модели дерева решений -  0.669\n"
     ]
    }
   ],
   "source": [
    "# создадим объект 'model' структуры данных DecisionTreeClassifier\n",
    "# зададим псевдослучайность random_state=12345\n",
    "model = DecisionTreeClassifier(random_state=12345,\n",
    "                               class_weight='balanced')\n",
    "\n",
    "# обучим модель на обучающей выборке\n",
    "model.fit(features_train, target_train)\n",
    "\n",
    "# произведем предсказания на валидационной выборке\n",
    "predictions = model.predict(features_valid)\n",
    "\n",
    "# качество предсказаний на валидационной выборке\n",
    "# f1-метрика\n",
    "print('F1-метрика с взвешиванием классов модели дерева решений - ', np.round(f1_score(target_valid, predictions),3))\n",
    "\n",
    "# roc_auc_score\n",
    "# для расчета метрики area under ROC-curve необходимо вычислить вероятности класса \"1\" \n",
    "probabilities_valid = model.predict_proba(features_valid)\n",
    "probabilities_one_valid = probabilities_valid[:, 1]\n",
    "\n",
    "auc_roc = roc_auc_score(target_valid, probabilities_one_valid)\n",
    "print('AUC-ROC-метрика с взвешиванием классов модели дерева решений - ', np.round(auc_roc,3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* модифицированные гиперпараметры"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    depth        f1   auc_roc\n",
      "0       1  0.499490  0.692557\n",
      "1       2  0.541016  0.750181\n",
      "2       3  0.541016  0.798047\n",
      "3       4  0.528548  0.821008\n",
      "4       5  0.599156  0.831492\n",
      "5       6  0.559099  0.803956\n",
      "6       7  0.547809  0.787159\n",
      "7       8  0.521422  0.770030\n",
      "8       9  0.514027  0.758402\n",
      "9      10  0.512124  0.742716\n",
      "10     11  0.499500  0.712877\n",
      "11     12  0.493292  0.713697\n",
      "12     13  0.502155  0.708711\n",
      "13     14  0.498309  0.697090\n",
      "14     15  0.498262  0.693621\n",
      "15     16  0.484262  0.677500\n",
      "16     17  0.493917  0.684535\n",
      "17     18  0.483516  0.674325\n",
      "18     19  0.477132  0.669298\n",
      "19     20  0.475369  0.667334\n",
      "20     21  0.479012  0.669478\n",
      "21     22  0.479012  0.669478\n",
      "22     23  0.479012  0.669478\n",
      "23     24  0.479012  0.669478\n",
      "24     25  0.479012  0.669478\n",
      "25     26  0.479012  0.669478\n",
      "26     27  0.479012  0.669478\n",
      "27     28  0.479012  0.669478\n",
      "28     29  0.479012  0.669478\n",
      "29     30  0.479012  0.669478\n",
      "30     31  0.479012  0.669478\n",
      "31     32  0.479012  0.669478\n",
      "32     33  0.479012  0.669478\n",
      "33     34  0.479012  0.669478\n",
      "34     35  0.479012  0.669478\n",
      "35     36  0.479012  0.669478\n",
      "36     37  0.479012  0.669478\n",
      "37     38  0.479012  0.669478\n",
      "38     39  0.479012  0.669478\n",
      "39     40  0.479012  0.669478\n",
      "40     41  0.479012  0.669478\n",
      "41     42  0.479012  0.669478\n",
      "42     43  0.479012  0.669478\n",
      "43     44  0.479012  0.669478\n",
      "44     45  0.479012  0.669478\n",
      "45     46  0.479012  0.669478\n",
      "46     47  0.479012  0.669478\n",
      "47     48  0.479012  0.669478\n",
      "48     49  0.479012  0.669478\n",
      "49     50  0.479012  0.669478\n",
      "\n",
      "Параметры наилучшей модели дерева решений:\n",
      "   depth        f1   auc_roc\n",
      "4      5  0.599156  0.831492\n"
     ]
    }
   ],
   "source": [
    "# циклом переберем гиперпараметр 'max_depth' и подберем наилучшую модель дерева решений\n",
    "# результаты вычислений запишем в словарь списков\n",
    "data = {'depth':list(),\n",
    "        'f1':list(),\n",
    "        'auc_roc':list()}\n",
    "\n",
    "for tree_depth in range(1, 51, 1):\n",
    "    # создадим объект 'model' структуры данных DecisionTreeClassifier\n",
    "    # зададим псевдослучайность random_state=12345\n",
    "    model = DecisionTreeClassifier(random_state=12345,\n",
    "                                   class_weight='balanced',\n",
    "                                   max_depth=tree_depth)\n",
    "\n",
    "    # обучим модель на обучающей выборке\n",
    "    model.fit(features_train, target_train)\n",
    "\n",
    "    # произведем предсказания на валидационной выборке\n",
    "    predictions = model.predict(features_valid)\n",
    "\n",
    "    # качество предсказаний на валидационной выборке\n",
    "    # f1-метрика\n",
    "    data['f1'].append(f1_score(target_valid, predictions))\n",
    "    \n",
    "    # roc_auc_score\n",
    "    # для расчета метрики area under ROC-curve необходимо вычислить вероятности класса \"1\" \n",
    "    probabilities_valid = model.predict_proba(features_valid)\n",
    "    probabilities_one_valid = probabilities_valid[:, 1]\n",
    "\n",
    "    auc_roc_sc = roc_auc_score(target_valid, probabilities_one_valid)\n",
    "    data['auc_roc'].append(auc_roc_sc)\n",
    "    \n",
    "    # глубина дерева 'max_depth'\n",
    "    data['depth'].append(tree_depth)\n",
    "\n",
    "results = pd.DataFrame(data=data)\n",
    "print(results)\n",
    "print()\n",
    "print('Параметры наилучшей модели дерева решений:')\n",
    "print(results[results['f1'] == results['f1'].max()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Обучение модели случайного леса с взвешиванием классов"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* стандартные гиперпараметры"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-метрика с взвешиванием классов модели случайного леса -  0.54\n",
      "AUC-ROC-метрика с взвешиванием классов модели случайного леса -  0.81\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "# создадим объект 'model' структуры данных RandomForestClassifier\n",
    "# зададим псевдослучайность random_state=12345\n",
    "model = RandomForestClassifier(random_state=12345,\n",
    "                               class_weight='balanced')\n",
    "\n",
    "# обучим модель на обучающей выборке\n",
    "model.fit(features_train, target_train)\n",
    "\n",
    "# произведем предсказания на валидационной выборке\n",
    "predictions = model.predict(features_valid)\n",
    "\n",
    "# качество предсказаний на валидационной выборке\n",
    "# f1-метрика\n",
    "print('F1-метрика с взвешиванием классов модели случайного леса - ', np.round(f1_score(target_valid, predictions),3))\n",
    "\n",
    "# roc_auc_score\n",
    "# для расчета метрики area under ROC-curve необходимо вычислить вероятности класса \"1\" \n",
    "probabilities_valid = model.predict_proba(features_valid)\n",
    "probabilities_one_valid = probabilities_valid[:, 1]\n",
    "\n",
    "auc_roc = roc_auc_score(target_valid, probabilities_one_valid)\n",
    "print('AUC-ROC-метрика с взвешиванием классов модели случайного леса - ', np.round(auc_roc,3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* модифицированные гиперпараметры"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     est  depth        f1   auc_roc\n",
      "0      1      1  0.346440  0.581196\n",
      "1      1      2  0.402030  0.635538\n",
      "2      1      3  0.435049  0.699943\n",
      "3      1      4  0.449147  0.739314\n",
      "4      1      5  0.468832  0.740757\n",
      "..   ...    ...       ...       ...\n",
      "695   50     10  0.602978  0.850181\n",
      "696   50     11  0.606218  0.848830\n",
      "697   50     12  0.586630  0.846586\n",
      "698   50     13  0.582278  0.846336\n",
      "699   50     14  0.590116  0.840676\n",
      "\n",
      "[700 rows x 4 columns]\n",
      "\n",
      "Параметры наилучшей модели случайного леса:\n",
      "     est  depth        f1   auc_roc\n",
      "607   44      6  0.625514  0.851346\n"
     ]
    }
   ],
   "source": [
    "# циклом переберем гиперпараметр 'n_estimators' и 'max_depth' и подберем наилучшую модель\n",
    "# результаты вычислений запишем в словарь списков\n",
    "data = {'est':list(),\n",
    "        'depth':list(),\n",
    "        'f1':list(),\n",
    "        'auc_roc':list()}\n",
    "\n",
    "for est in range(1, 51, 1):\n",
    "    for tree_depth in range(1, 15, 1):\n",
    "        # создадим объект 'model' структуры данных RandomForestClassifier\n",
    "        # зададим псевдослучайность random_state=12345\n",
    "        model = RandomForestClassifier(random_state=12345,\n",
    "                                   class_weight='balanced',\n",
    "                                   n_estimators=est,\n",
    "                                   max_depth=tree_depth)\n",
    "\n",
    "        # обучим модель на обучающей выборке\n",
    "        model.fit(features_train, target_train)\n",
    "\n",
    "        # произведем предсказания на валидационной выборке\n",
    "        predictions = model.predict(features_valid)\n",
    "\n",
    "        # качество предсказаний на валидационной выборке\n",
    "        # f1-метрика\n",
    "        data['f1'].append(f1_score(target_valid, predictions))\n",
    "    \n",
    "        # roc_auc_score\n",
    "        # для расчета метрики area under ROC-curve необходимо вычислить вероятности класса \"1\" \n",
    "        probabilities_valid = model.predict_proba(features_valid)\n",
    "        probabilities_one_valid = probabilities_valid[:, 1]\n",
    "\n",
    "        auc_roc_sc = roc_auc_score(target_valid, probabilities_one_valid)\n",
    "        data['auc_roc'].append(auc_roc_sc)\n",
    "    \n",
    "        # кол-во деревьев в лесу\n",
    "        data['est'].append(est)\n",
    "\n",
    "        # глубина дерева 'max_depth'\n",
    "        data['depth'].append(tree_depth)\n",
    "    \n",
    "results = pd.DataFrame(data=data)\n",
    "print(results)\n",
    "print()\n",
    "print('Параметры наилучшей модели случайного леса:')\n",
    "print(results[results['f1'] == results['f1'].max()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Обучение модели логистической регрессии с взвешиванием классов"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* взвешивание классов логистической регрессии"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-метрика с взвешиванием классов модели логистической регрессии -  0.496\n",
      "AUC-ROC-метрика с взвешиванием классов модели логистической регрессии -  0.75\n"
     ]
    }
   ],
   "source": [
    "# создадим объект 'model' структуры данных LogisticRegression\n",
    "# зададим псевдослучайность random_state=12345\n",
    "model = LogisticRegression(random_state=12345,\n",
    "                           solver='liblinear',\n",
    "                           class_weight='balanced')\n",
    "\n",
    "# обучим модель на обучающей выборке\n",
    "model.fit(features_train, target_train)\n",
    "\n",
    "# произведем предсказания на валидационной выборке\n",
    "predictions = model.predict(features_valid)\n",
    "\n",
    "# качество предсказаний на валидационной выборке\n",
    "# f1-метрика\n",
    "print('F1-метрика с взвешиванием классов модели логистической регрессии - ', np.round(f1_score(target_valid, predictions),3))\n",
    "\n",
    "# roc_auc_score\n",
    "# для расчета метрики area under ROC-curve необходимо вычислить вероятности класса \"1\" \n",
    "probabilities_valid = model.predict_proba(features_valid)\n",
    "probabilities_one_valid = probabilities_valid[:, 1]\n",
    "\n",
    "auc_roc = roc_auc_score(target_valid, probabilities_one_valid)\n",
    "print('AUC-ROC-метрика с взвешиванием классов модели логистической регрессии - ', np.round(auc_roc,3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Вывод"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Были обучены модели дерева решений, случайного леса, логистической регрессии с учетом дисбаланса классов путем их взвешивания;\n",
    "\n",
    "2. Рассчитаны метрики качества F1 и AUC-ROC для каждой модели:\n",
    "\n",
    "\n",
    "\n",
    "* **Стандартные гиперпараметры:**\n",
    "\n",
    "  2.1 F1-метрика с учетом дисбаланса классов для моделей:\n",
    "    * дерева решений - `0.479`\n",
    "    * случайного леса - `0.54`\n",
    "    * логистической регрессии - `0.496`\n",
    "\n",
    "  2.2 AUC-ROC-метрика с учетом дисбаланса классов для моделей:\n",
    "    * дерева решений - `0.669`\n",
    "    * случайного леса - `0.81`\n",
    "    * логистической регрессии - `0.75`\n",
    "\n",
    "\n",
    "* **Модифицированные гиперпараметры:**\n",
    "\n",
    "  2.3 F1-метрика с учетом дисбаланса классов для моделей:\n",
    "    * наилучшая модель дерева решений `глубиной 5` - `0.599`\n",
    "    * наилучшая модель случайного леса с количеством деревьев в ансамбле `44` и глубиной дерева `6` - `0.626`\n",
    "\n",
    "  2.4 AUC-ROC-метрика с учетом дисбаланса классов для моделей:\n",
    "    * наилучшая модель дерева решений `глубиной 5` - `0.832` \n",
    "    * наилучшая модель случайного леса с количеством деревьев в ансамбле `44` и глубиной дерева `6` - `0.851`\n",
    "\n",
    "\n",
    "\n",
    "3. `Наилучшие результаты` с учетом дисбаланса классов путем их взвешивания и предельно большим значением F1-меры на валидационной выборке показала `модель случайного леса с количеством деревьев в ансамбле равным 44 и глубиной дерева 6`: \n",
    "    * F1 - `0.626`\n",
    "    * AUC-ROC - `0.851`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Изменение порога логистической регрессии"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Выполним изменение порога логистической регрессии для несбалансированных классов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    threshold        f1\n",
      "0        0.00  0.345740\n",
      "1        0.05  0.345740\n",
      "2        0.10  0.345740\n",
      "3        0.15  0.370370\n",
      "4        0.20  0.366667\n",
      "5        0.25  0.200253\n",
      "6        0.30  0.048458\n",
      "7        0.35  0.004773\n",
      "8        0.40  0.000000\n",
      "9        0.45  0.000000\n",
      "10       0.50  0.000000\n",
      "11       0.55  0.000000\n",
      "12       0.60  0.000000\n",
      "13       0.65  0.000000\n",
      "14       0.70  0.000000\n",
      "15       0.75  0.000000\n",
      "16       0.80  0.000000\n",
      "17       0.85  0.000000\n",
      "\n",
      "Наилучшие показатели F1-меры при изменении порога логистической регрессии для несбалансированных классов:\n",
      "   threshold       f1\n",
      "3       0.15  0.37037\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "# циклом переберем гиперпараметр 'n_estimators' и 'max_depth' и подберем наилучшую модель\n",
    "# результаты вычислений запишем в словарь списков\n",
    "data = {'threshold':list(),\n",
    "        'f1':list()}\n",
    "\n",
    "# создадим объект 'model' структуры данных LogisticRegression\n",
    "# зададим псевдослучайность random_state=12345\n",
    "model = LogisticRegression(random_state=12345,\n",
    "                           solver='liblinear')\n",
    "\n",
    "# обучим модель на обучающей выборке\n",
    "model.fit(features_train, target_train)\n",
    "\n",
    "# вычислим вероятности получения класса \"1\" \n",
    "probabilities_valid = model.predict_proba(features_valid)\n",
    "probabilities_one_valid = probabilities_valid[:, 1]\n",
    "\n",
    "# циклом переберем пороги для логистической регрессии и вычислим f1\n",
    "for threshold in np.arange(0, 0.9, 0.05):\n",
    "    # произведем предсказания на валидационной выборке путем отсечения вероятностей по порогам\n",
    "    predictions = probabilities_one_valid > threshold\n",
    "    \n",
    "    # добавляем порог и рассчитанную f1-метрику в словарь\n",
    "    data['threshold'].append(threshold)\n",
    "    data['f1'].append(f1_score(target_valid, predictions))\n",
    "\n",
    "results = pd.DataFrame(data=data)\n",
    "print(results)\n",
    "print()\n",
    "print('Наилучшие показатели F1-меры при изменении порога логистической регрессии для несбалансированных классов:')\n",
    "print(results[results['f1'] == results['f1'].max()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Вывод"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Выполнено изменение порога логистической регрессии для несбалансированных классов;\n",
    "2. Наилучшие показатели F1-меры при изменении порога для несбалансированных классов показала модель логистической регрессии с `порогом 0.15` и значением `F1-меры -  0.37`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Увеличение выборки"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Техника `upsampling` (увеличение выборки) заключается в увеличении количества объектов редкого класса в выборке с целью улучшения предсказаний. В нашем случае редким классом являются объекты `класса 1`. Проведем `upsampling` класса 1 на обучающей выборке, обучим модели, рассчитаем F1-меру.\n",
    "\n",
    "* проведем `upsampling` класса 1 на обучающей выборке"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# напишем функцию, которая увеличит кол-во объектов обучающей выборки с классом '1'\n",
    "\n",
    "# множитель для увеличения рассчитаем, исходя из данных, полученных в п.3.1\n",
    "# округлим до целого\n",
    "repeat = np.int_(np.round(zero_class/one_class)) \n",
    "\n",
    "def upsampling(features, target, repeat):\n",
    "    \n",
    "    features_zeros = features[target == 0]\n",
    "    features_ones = features[target == 1]\n",
    "    target_zeros = target[target == 0]\n",
    "    target_ones = target[target == 1]\n",
    "\n",
    "    features_upsampled = pd.concat([features_zeros] + [features_ones] * repeat)\n",
    "    target_upsampled = pd.concat([target_zeros] + [target_ones] * repeat)\n",
    "    \n",
    "    features_upsampled, target_upsampled = shuffle(features_upsampled,\n",
    "                                                   target_upsampled,\n",
    "                                                   random_state=12345)\n",
    "\n",
    "    return features_upsampled, target_upsampled\n",
    "\n",
    "features_upsampled, target_upsampled = upsampling(features_train, target_train, repeat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Обучение модели дерева решений на увеличенной выборке"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    depth        f1   auc_roc\n",
      "0       1  0.499490  0.692557\n",
      "1       2  0.541016  0.750181\n",
      "2       3  0.541016  0.798047\n",
      "3       4  0.528548  0.821008\n",
      "4       5  0.599156  0.831492\n",
      "5       6  0.559099  0.803978\n",
      "6       7  0.550696  0.791572\n",
      "7       8  0.523416  0.771127\n",
      "8       9  0.511416  0.754102\n",
      "9      10  0.519174  0.743883\n",
      "10     11  0.505976  0.719416\n",
      "11     12  0.487603  0.711382\n",
      "12     13  0.503240  0.708859\n",
      "13     14  0.515766  0.709431\n",
      "14     15  0.514552  0.701776\n",
      "15     16  0.487455  0.682916\n",
      "16     17  0.489747  0.682828\n",
      "17     18  0.478736  0.671027\n",
      "18     19  0.485366  0.674178\n",
      "19     20  0.475610  0.667674\n",
      "20     21  0.486553  0.674511\n",
      "21     22  0.486553  0.674511\n",
      "22     23  0.486553  0.674511\n",
      "23     24  0.486553  0.674511\n",
      "24     25  0.486553  0.674511\n",
      "\n",
      "Параметры наилучшей модели дерева решений:\n",
      "   depth        f1   auc_roc\n",
      "4      5  0.599156  0.831492\n"
     ]
    }
   ],
   "source": [
    "# циклом переберем гиперпараметр 'max_depth' и подберем наилучшую модель дерева решений\n",
    "# результаты вычислений запишем в словарь списков\n",
    "data = {'depth':list(),\n",
    "        'f1':list(),\n",
    "        'auc_roc':list()}\n",
    "\n",
    "for tree_depth in range(1, 26, 1):\n",
    "    # создадим объект 'model' структуры данных DecisionTreeClassifier\n",
    "    # зададим псевдослучайность random_state=12345\n",
    "    model = DecisionTreeClassifier(random_state=12345,\n",
    "                                   max_depth=tree_depth)\n",
    "\n",
    "    # обучим модель на обучающей МОДИФИЦИРОВАННОЙ выборке\n",
    "    model.fit(features_upsampled, target_upsampled)\n",
    "\n",
    "    # произведем предсказания на валидационной выборке\n",
    "    predictions = model.predict(features_valid)\n",
    "\n",
    "    # качество предсказаний на валидационной выборке\n",
    "    # f1-метрика\n",
    "    data['f1'].append(f1_score(target_valid, predictions))\n",
    "    \n",
    "    # roc_auc_score\n",
    "    # для расчета метрики area under ROC-curve необходимо вычислить вероятности класса \"1\" \n",
    "    probabilities_valid = model.predict_proba(features_valid)\n",
    "    probabilities_one_valid = probabilities_valid[:, 1]\n",
    "\n",
    "    auc_roc_sc = roc_auc_score(target_valid, probabilities_one_valid)\n",
    "    data['auc_roc'].append(auc_roc_sc)\n",
    "    \n",
    "    # глубина дерева 'max_depth'\n",
    "    data['depth'].append(tree_depth)\n",
    "\n",
    "results = pd.DataFrame(data=data)\n",
    "print(results)\n",
    "print()\n",
    "print('Параметры наилучшей модели дерева решений:')\n",
    "print(results[results['f1'] == results['f1'].max()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Обучение модели случайного леса на увеличенной выборке"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     est  depth        f1   auc_roc\n",
      "0      1      1  0.346440  0.581196\n",
      "1      1      2  0.402030  0.639084\n",
      "2      1      3  0.432990  0.696539\n",
      "3      1      4  0.455446  0.744629\n",
      "4      1      5  0.491018  0.756270\n",
      "..   ...    ...       ...       ...\n",
      "695   50     10  0.616408  0.853938\n",
      "696   50     11  0.609393  0.847504\n",
      "697   50     12  0.607059  0.843692\n",
      "698   50     13  0.595797  0.844997\n",
      "699   50     14  0.608365  0.840958\n",
      "\n",
      "[700 rows x 4 columns]\n",
      "\n",
      "Параметры наилучшей модели случайного леса:\n",
      "     est  depth        f1   auc_roc\n",
      "663   48      6  0.625641  0.850852\n"
     ]
    }
   ],
   "source": [
    "# циклом переберем гиперпараметр 'n_estimators' и 'max_depth' и подберем наилучшую модель\n",
    "# результаты вычислений запишем в словарь списков\n",
    "data = {'est':list(),\n",
    "        'depth':list(),\n",
    "        'f1':list(),\n",
    "        'auc_roc':list()}\n",
    "\n",
    "for est in range(1, 51, 1):\n",
    "    for tree_depth in range(1, 15, 1):\n",
    "        # создадим объект 'model' структуры данных RandomForestClassifier\n",
    "        # зададим псевдослучайность random_state=12345\n",
    "        model = RandomForestClassifier(random_state=12345,\n",
    "                                       n_estimators=est,\n",
    "                                       max_depth=tree_depth)\n",
    "\n",
    "        # обучим модель на обучающей МОДИФИЦИРОВАННОЙ выборке\n",
    "        model.fit(features_upsampled, target_upsampled)\n",
    "\n",
    "        # произведем предсказания на валидационной выборке\n",
    "        predictions = model.predict(features_valid)\n",
    "\n",
    "        # качество предсказаний на валидационной выборке\n",
    "        # f1-метрика\n",
    "        data['f1'].append(f1_score(target_valid, predictions))\n",
    "    \n",
    "        # roc_auc_score\n",
    "        # для расчета метрики area under ROC-curve необходимо вычислить вероятности класса \"1\" \n",
    "        probabilities_valid = model.predict_proba(features_valid)\n",
    "        probabilities_one_valid = probabilities_valid[:, 1]\n",
    "\n",
    "        auc_roc_sc = roc_auc_score(target_valid, probabilities_one_valid)\n",
    "        data['auc_roc'].append(auc_roc_sc)\n",
    "    \n",
    "        # кол-во деревьев в лесу\n",
    "        data['est'].append(est)\n",
    "\n",
    "        # глубина дерева 'max_depth'\n",
    "        data['depth'].append(tree_depth)\n",
    "    \n",
    "results = pd.DataFrame(data=data)\n",
    "print(results)\n",
    "print()\n",
    "print('Параметры наилучшей модели случайного леса:')\n",
    "print(results[results['f1'] == results['f1'].max()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Обучение модели логистической регрессии на увеличенной выборке"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-метрика модели логистической регрессии на увеличенной выборке -  0.456\n",
      "AUC-ROC-метрика модели логистической регрессии на увеличенной выборке -  0.728\n"
     ]
    }
   ],
   "source": [
    "# создадим объект 'model' структуры данных LogisticRegression\n",
    "# зададим псевдослучайность random_state=12345\n",
    "model = LogisticRegression(random_state=12345,\n",
    "                           solver='liblinear')\n",
    "\n",
    "# обучим модель на обучающей выборке\n",
    "model.fit(features_upsampled, target_upsampled)\n",
    "\n",
    "# произведем предсказания на валидационной выборке\n",
    "predictions = model.predict(features_valid)\n",
    "\n",
    "# качество предсказаний на валидационной выборке\n",
    "# f1-метрика\n",
    "print('F1-метрика модели логистической регрессии на увеличенной выборке - ', np.round(f1_score(target_valid, predictions),3))\n",
    "\n",
    "# roc_auc_score\n",
    "# для расчета метрики area under ROC-curve необходимо вычислить вероятности класса \"1\" \n",
    "probabilities_valid = model.predict_proba(features_valid)\n",
    "probabilities_one_valid = probabilities_valid[:, 1]\n",
    "\n",
    "auc_roc = roc_auc_score(target_valid, probabilities_one_valid)\n",
    "print('AUC-ROC-метрика модели логистической регрессии на увеличенной выборке - ', np.round(auc_roc,3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Вывод"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Были обучены модели дерева решений, случайного леса, логистической регрессии с учетом дисбаланса классов `методом upsampling` (увеличение объектов редкого класса);\n",
    "\n",
    "2. Рассчитаны метрики качества F1 и AUC-ROC для каждой модели:\n",
    "\n",
    "    2.3 F1-метрика с учетом дисбаланса классов для моделей:\n",
    "    * наилучшая модель дерева решений `глубиной 5` - `0.599`\n",
    "    * наилучшая модель случайного леса с количеством деревьев в ансамбле `48` и глубиной дерева `6` - `0.626`\n",
    "    * модель логистической регрессии на увеличенной выборке -  `0.456`\n",
    "\n",
    "    2.4 AUC-ROC-метрика с учетом дисбаланса классов для моделей:\n",
    "    * наилучшая модель дерева решений `глубиной 5` - `0.832` \n",
    "    * наилучшая модель случайного леса с количеством деревьев в ансамбле `48` и глубиной дерева `6` - `0.851`\n",
    "    * модель логистической регрессии на увеличенной выборке -  `0.728`\n",
    "\n",
    "3. `Наилучшие результаты` с учетом дисбаланса классов `методом upsampling` (увеличение объектов редкого класса) и предельно большим значением F1-меры на валидационной выборке показала `модель случайного леса с количеством деревьев в ансамбле равным 48 и глубиной дерева 6`: \n",
    "    * F1 - `0.626`\n",
    "    * AUC-ROC - `0.851`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Уменьшение выборки"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Техника `downsampling` (уменьшение выборки) заключается в уменьшении количества объектов частого класса в выборке с целью улучшения предсказаний. В нашем случае частым классом являются объекты `класса 0`. Проведем `downsampling` класса 0 на обучающей выборке, обучим модели, рассчитаем F1-меру.\n",
    "\n",
    "* проведем `downsampling` класса 0 на обучающей выборке"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# напишем функцию, которая уменьшит кол-во объектов обучающей выборки с классом '0'\n",
    "\n",
    "# долю объектов обучающей выборки с классом '0' рассчитаем, исходя из данных, полученных в п.3.1\n",
    "# округлим до целого\n",
    "fraction = np.round(one_class/zero_class, 2) \n",
    "\n",
    "def downsampling(features, target, fraction):\n",
    "    \n",
    "    features_zeros = features[target == 0]\n",
    "    features_ones = features[target == 1]\n",
    "    target_zeros = target[target == 0]\n",
    "    target_ones = target[target == 1]\n",
    "\n",
    "    features_downsampled = pd.concat([features_zeros.sample(frac=fraction, random_state=12345)]\n",
    "                                     +[features_ones])\n",
    "    target_downsampled = pd.concat([target_zeros.sample(frac=fraction, random_state=12345)]\n",
    "                                   +[target_ones])\n",
    "    \n",
    "    features_downsampled, target_downsampled = shuffle(features_downsampled,\n",
    "                                                       target_downsampled,\n",
    "                                                       random_state=12345)\n",
    "\n",
    "    return features_downsampled, target_downsampled\n",
    "\n",
    "features_downsampled, target_downsampled = downsampling(features_train, target_train, fraction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Обучение модели дерева решений на уменьшенной выборке"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    depth        f1   auc_roc\n",
      "0       1  0.506185  0.702189\n",
      "1       2  0.539450  0.757889\n",
      "2       3  0.555235  0.800989\n",
      "3       4  0.542149  0.817139\n",
      "4       5  0.577398  0.824906\n",
      "5       6  0.574906  0.814866\n",
      "6       7  0.541744  0.803785\n",
      "7       8  0.542056  0.780580\n",
      "8       9  0.528715  0.756882\n",
      "9      10  0.503534  0.731191\n",
      "10     11  0.505809  0.727956\n",
      "11     12  0.496528  0.712873\n",
      "12     13  0.492729  0.705093\n",
      "13     14  0.483516  0.698116\n",
      "14     15  0.479730  0.691665\n",
      "15     16  0.481702  0.694229\n",
      "16     17  0.484848  0.696564\n",
      "17     18  0.480801  0.688900\n",
      "18     19  0.483682  0.691459\n",
      "19     20  0.483682  0.691459\n",
      "20     21  0.483682  0.691459\n",
      "21     22  0.483682  0.691459\n",
      "22     23  0.483682  0.691459\n",
      "23     24  0.483682  0.691459\n",
      "24     25  0.483682  0.691459\n",
      "\n",
      "Параметры наилучшей модели дерева решений:\n",
      "   depth        f1   auc_roc\n",
      "4      5  0.577398  0.824906\n"
     ]
    }
   ],
   "source": [
    "# циклом переберем гиперпараметр 'max_depth' и подберем наилучшую модель дерева решений\n",
    "# результаты вычислений запишем в словарь списков\n",
    "data = {'depth':list(),\n",
    "        'f1':list(),\n",
    "        'auc_roc':list()}\n",
    "\n",
    "for tree_depth in range(1, 26, 1):\n",
    "    # создадим объект 'model' структуры данных DecisionTreeClassifier\n",
    "    # зададим псевдослучайность random_state=12345\n",
    "    model = DecisionTreeClassifier(random_state=12345,\n",
    "                                   max_depth=tree_depth)\n",
    "\n",
    "    # обучим модель на обучающей МОДИФИЦИРОВАННОЙ выборке\n",
    "    model.fit(features_downsampled, target_downsampled)\n",
    "\n",
    "    # произведем предсказания на валидационной выборке\n",
    "    predictions = model.predict(features_valid)\n",
    "\n",
    "    # качество предсказаний на валидационной выборке\n",
    "    # f1-метрика\n",
    "    data['f1'].append(f1_score(target_valid, predictions))\n",
    "    \n",
    "    # roc_auc_score\n",
    "    # для расчета метрики area under ROC-curve необходимо вычислить вероятности класса \"1\" \n",
    "    probabilities_valid = model.predict_proba(features_valid)\n",
    "    probabilities_one_valid = probabilities_valid[:, 1]\n",
    "\n",
    "    auc_roc_sc = roc_auc_score(target_valid, probabilities_one_valid)\n",
    "    data['auc_roc'].append(auc_roc_sc)\n",
    "    \n",
    "    # глубина дерева 'max_depth'\n",
    "    data['depth'].append(tree_depth)\n",
    "\n",
    "results = pd.DataFrame(data=data)\n",
    "print(results)\n",
    "print()\n",
    "print('Параметры наилучшей модели дерева решений:')\n",
    "print(results[results['f1'] == results['f1'].max()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Обучение модели случайного леса на уменьшенной выборке"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     est  depth        f1   auc_roc\n",
      "0      1      1  0.346440  0.581196\n",
      "1      1      2  0.401077  0.639084\n",
      "2      1      3  0.403292  0.686232\n",
      "3      1      4  0.424354  0.735329\n",
      "4      1      5  0.458333  0.734300\n",
      "..   ...    ...       ...       ...\n",
      "695   50     10  0.586437  0.846032\n",
      "696   50     11  0.588899  0.846854\n",
      "697   50     12  0.585507  0.846335\n",
      "698   50     13  0.576303  0.845357\n",
      "699   50     14  0.579245  0.843886\n",
      "\n",
      "[700 rows x 4 columns]\n",
      "\n",
      "Параметры наилучшей модели случайного леса:\n",
      "     est  depth        f1   auc_roc\n",
      "691   50      6  0.615234  0.847336\n"
     ]
    }
   ],
   "source": [
    "# циклом переберем гиперпараметр 'n_estimators' и 'max_depth' и подберем наилучшую модель\n",
    "# результаты вычислений запишем в словарь списков\n",
    "data = {'est':list(),\n",
    "        'depth':list(),\n",
    "        'f1':list(),\n",
    "        'auc_roc':list()}\n",
    "\n",
    "for est in range(1, 51, 1):\n",
    "    for tree_depth in range(1, 15, 1):\n",
    "        # создадим объект 'model' структуры данных RandomForestClassifier\n",
    "        # зададим псевдослучайность random_state=12345\n",
    "        model = RandomForestClassifier(random_state=12345,\n",
    "                                       n_estimators=est,\n",
    "                                       max_depth=tree_depth)\n",
    "\n",
    "        # обучим модель на обучающей МОДИФИЦИРОВАННОЙ выборке\n",
    "        model.fit(features_downsampled, target_downsampled)\n",
    "\n",
    "        # произведем предсказания на валидационной выборке\n",
    "        predictions = model.predict(features_valid)\n",
    "\n",
    "        # качество предсказаний на валидационной выборке\n",
    "        # f1-метрика\n",
    "        data['f1'].append(f1_score(target_valid, predictions))\n",
    "    \n",
    "        # roc_auc_score\n",
    "        # для расчета метрики area under ROC-curve необходимо вычислить вероятности класса \"1\" \n",
    "        probabilities_valid = model.predict_proba(features_valid)\n",
    "        probabilities_one_valid = probabilities_valid[:, 1]\n",
    "\n",
    "        auc_roc_sc = roc_auc_score(target_valid, probabilities_one_valid)\n",
    "        data['auc_roc'].append(auc_roc_sc)\n",
    "    \n",
    "        # кол-во деревьев в лесу\n",
    "        data['est'].append(est)\n",
    "\n",
    "        # глубина дерева 'max_depth'\n",
    "        data['depth'].append(tree_depth)\n",
    "    \n",
    "results = pd.DataFrame(data=data)\n",
    "print(results)\n",
    "print()\n",
    "print('Параметры наилучшей модели случайного леса:')\n",
    "print(results[results['f1'] == results['f1'].max()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Обучение модели логистической регрессии на уменьшенной выборке"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-метрика модели логистической регрессии на уменьшенной выборке -  0.358\n",
      "AUC-ROC-метрика модели логистической регрессии на уменьшенной выборке -  0.564\n"
     ]
    }
   ],
   "source": [
    "# создадим объект 'model' структуры данных LogisticRegression\n",
    "# зададим псевдослучайность random_state=12345\n",
    "model = LogisticRegression(random_state=12345,\n",
    "                           solver='liblinear')\n",
    "\n",
    "# обучим модель на обучающей выборке\n",
    "model.fit(features_downsampled, target_downsampled)\n",
    "\n",
    "# произведем предсказания на валидационной выборке\n",
    "predictions = model.predict(features_valid)\n",
    "\n",
    "# качество предсказаний на валидационной выборке\n",
    "# f1-метрика\n",
    "print('F1-метрика модели логистической регрессии на уменьшенной выборке - ', np.round(f1_score(target_valid, predictions),3))\n",
    "\n",
    "# roc_auc_score\n",
    "# для расчета метрики area under ROC-curve необходимо вычислить вероятности класса \"1\" \n",
    "probabilities_valid = model.predict_proba(features_valid)\n",
    "probabilities_one_valid = probabilities_valid[:, 1]\n",
    "\n",
    "auc_roc = roc_auc_score(target_valid, probabilities_one_valid)\n",
    "print('AUC-ROC-метрика модели логистической регрессии на уменьшенной выборке - ', np.round(auc_roc,3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Вывод"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Были обучены модели дерева решений, случайного леса, логистической регрессии с учетом дисбаланса классов `методом downsampling` (уменьшение объектов частого класса);\n",
    "\n",
    "\n",
    "2. Рассчитаны метрики качества F1 и AUC-ROC для каждой модели:\n",
    "\n",
    "    2.3 F1-метрика с учетом дисбаланса классов для моделей:\n",
    "    * наилучшая модель дерева решений `глубиной 5` - `0.577`\n",
    "    * наилучшая модель случайного леса с количеством деревьев в ансамбле `50` и глубиной дерева `6` - `0.615`\n",
    "    * модель логистической регрессии на уменьшенной выборке -  `0.358`\n",
    "\n",
    "    2.4 AUC-ROC-метрика с учетом дисбаланса классов для моделей:\n",
    "    * наилучшая модель дерева решений `глубиной 5` - `0.825` \n",
    "    * наилучшая модель случайного леса с количеством деревьев в ансамбле `50` и глубиной дерева `6` - `0.847`\n",
    "    * модель логистической регрессии на увеличенной выборке -  `0.564`\n",
    "\n",
    "\n",
    "3. `Наилучшие результаты` с учетом дисбаланса классов `методом downsampling` (уменьшение объектов частого класса) и предельно большим значением F1-меры на валидационной выборке показала `модель случайного леса с количеством деревьев в ансамбле равным 50 и глубиной дерева 6`: \n",
    "    * F1 - `0.615`\n",
    "    * AUC-ROC - `0.847`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Масштабирование признаков"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Техника `масштабирования признаков` заключается в приведении числовых признаков выборки к единому масштабу от 0 до 1 с целью улучшения предсказаний. Стоит отметить, что бинарные признаки из столбцов `hascrcard,\tisactivemember, exited, geography_germany, geography_spain, gender_male`, а также `customerid` - масштабировать не требуется.\n",
    "\n",
    "Проведем масштабирование признаков обучающей выборки в следующих столбцах: `creditscore, age, tenure, balance, numofproducts, estimatedsalary`. Далее обучим модели, рассчитаем необходимые метрики качества."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# в переменной 'numeric' перечислим необходимые столбцы для масштабирования\n",
    "numeric = ['creditscore', 'age', 'tenure', 'balance', 'numofproducts', 'estimatedsalary']\n",
    "\n",
    "# создадим объект 'scaler' структуры данных StandardScaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# в дальнейшем будем работать с копиями обучающей и валидационной выборок\n",
    "features_train_scaled = features_train.copy()\n",
    "features_valid_scaled = features_valid.copy()\n",
    "\n",
    "# обучим 'scaler' на обучающей выборке столбцов переменной 'numeric'\n",
    "scaler.fit(features_train_scaled[numeric])\n",
    "\n",
    "# Чтобы предупреждение 'SettingWithCopy' не появлялось, в код добавляют строчку:\n",
    "pd.options.mode.chained_assignment = None\n",
    "\n",
    "# проведем масштабирование признаков в столбцах переменной 'numeric' у обучающей и валидационной выборок\n",
    "features_train_scaled[numeric] = scaler.transform(features_train_scaled[numeric])\n",
    "features_valid_scaled[numeric] = scaler.transform(features_valid_scaled[numeric])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Обучение модели дерева решений на масштабированной выборке"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    depth        f1   auc_roc\n",
      "0       1  0.000000  0.692557\n",
      "1       2  0.521739  0.750181\n",
      "2       3  0.423488  0.797344\n",
      "3       4  0.552870  0.815352\n",
      "4       5  0.541471  0.823335\n",
      "5       6  0.572714  0.823576\n",
      "6       7  0.543779  0.816721\n",
      "7       8  0.559524  0.807656\n",
      "8       9  0.573034  0.781817\n",
      "9      10  0.532562  0.767779\n",
      "10     11  0.520216  0.748143\n",
      "11     12  0.511082  0.715635\n",
      "12     13  0.497409  0.690696\n",
      "13     14  0.490613  0.683253\n",
      "14     15  0.485820  0.674567\n",
      "15     16  0.511166  0.687134\n",
      "16     17  0.487805  0.668486\n",
      "17     18  0.496970  0.676558\n",
      "18     19  0.485066  0.671306\n",
      "19     20  0.496503  0.679867\n",
      "20     21  0.486874  0.674735\n",
      "21     22  0.488889  0.678330\n",
      "22     23  0.497653  0.683268\n",
      "23     24  0.489893  0.677827\n",
      "24     25  0.489893  0.677827\n",
      "\n",
      "Параметры наилучшей модели дерева решений:\n",
      "   depth        f1   auc_roc\n",
      "8      9  0.573034  0.781817\n"
     ]
    }
   ],
   "source": [
    "# циклом переберем гиперпараметр 'max_depth' и подберем наилучшую модель дерева решений\n",
    "# результаты вычислений запишем в словарь списков\n",
    "data = {'depth':list(),\n",
    "        'f1':list(),\n",
    "        'auc_roc':list()}\n",
    "\n",
    "for tree_depth in range(1, 26, 1):\n",
    "    # создадим объект 'model' структуры данных DecisionTreeClassifier\n",
    "    # зададим псевдослучайность random_state=12345\n",
    "    model = DecisionTreeClassifier(random_state=12345,\n",
    "                                   max_depth=tree_depth)\n",
    "\n",
    "    # обучим модель на обучающей МАСШТАБИРОВАННОЙ выборке\n",
    "    model.fit(features_train_scaled, target_train)\n",
    "\n",
    "    # произведем предсказания на валидационной выборке\n",
    "    predictions = model.predict(features_valid_scaled)\n",
    "\n",
    "    # качество предсказаний на валидационной выборке\n",
    "    # f1-метрика\n",
    "    data['f1'].append(f1_score(target_valid, predictions))\n",
    "    \n",
    "    # roc_auc_score\n",
    "    # для расчета метрики area under ROC-curve необходимо вычислить вероятности класса \"1\" \n",
    "    probabilities_valid = model.predict_proba(features_valid_scaled)\n",
    "    probabilities_one_valid = probabilities_valid[:, 1]\n",
    "\n",
    "    auc_roc_sc = roc_auc_score(target_valid, probabilities_one_valid)\n",
    "    data['auc_roc'].append(auc_roc_sc)\n",
    "    \n",
    "    # глубина дерева 'max_depth'\n",
    "    data['depth'].append(tree_depth)\n",
    "\n",
    "results = pd.DataFrame(data=data)\n",
    "print(results)\n",
    "print()\n",
    "print('Параметры наилучшей модели дерева решений:')\n",
    "print(results[results['f1'] == results['f1'].max()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Обучение модели случайного леса на масштабированной выборке"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     est  depth        f1   auc_roc\n",
      "0      1      1  0.000000  0.581196\n",
      "1      1      2  0.248473  0.635538\n",
      "2      1      3  0.146868  0.698878\n",
      "3      1      4  0.427432  0.739314\n",
      "4      1      5  0.269531  0.748031\n",
      "..   ...    ...       ...       ...\n",
      "695   50     10  0.573209  0.843350\n",
      "696   50     11  0.580645  0.846969\n",
      "697   50     12  0.583587  0.846223\n",
      "698   50     13  0.591463  0.839881\n",
      "699   50     14  0.573620  0.839924\n",
      "\n",
      "[700 rows x 4 columns]\n",
      "\n",
      "Параметры наилучшей модели случайного леса:\n",
      "     est  depth        f1   auc_roc\n",
      "487   35     12  0.596067  0.847887\n"
     ]
    }
   ],
   "source": [
    "# циклом переберем гиперпараметр 'n_estimators' и 'max_depth' и подберем наилучшую модель\n",
    "# результаты вычислений запишем в словарь списков\n",
    "data = {'est':list(),\n",
    "        'depth':list(),\n",
    "        'f1':list(),\n",
    "        'auc_roc':list()}\n",
    "\n",
    "for est in range(1, 51, 1):\n",
    "    for tree_depth in range(1, 15, 1):\n",
    "        # создадим объект 'model' структуры данных RandomForestClassifier\n",
    "        # зададим псевдослучайность random_state=12345\n",
    "        model = RandomForestClassifier(random_state=12345,\n",
    "                                       n_estimators=est,\n",
    "                                       max_depth=tree_depth)\n",
    "\n",
    "        # обучим модель на обучающей МАСШТАБИРОВАННОЙ выборке\n",
    "        model.fit(features_train_scaled, target_train)\n",
    "\n",
    "        # произведем предсказания на валидационной выборке\n",
    "        predictions = model.predict(features_valid_scaled)\n",
    "\n",
    "        # качество предсказаний на валидационной выборке\n",
    "        # f1-метрика\n",
    "        data['f1'].append(f1_score(target_valid, predictions))\n",
    "    \n",
    "        # roc_auc_score\n",
    "        # для расчета метрики area under ROC-curve необходимо вычислить вероятности класса \"1\" \n",
    "        probabilities_valid = model.predict_proba(features_valid_scaled)\n",
    "        probabilities_one_valid = probabilities_valid[:, 1]\n",
    "\n",
    "        auc_roc_sc = roc_auc_score(target_valid, probabilities_one_valid)\n",
    "        data['auc_roc'].append(auc_roc_sc)\n",
    "    \n",
    "        # кол-во деревьев в лесу\n",
    "        data['est'].append(est)\n",
    "\n",
    "        # глубина дерева 'max_depth'\n",
    "        data['depth'].append(tree_depth)\n",
    "    \n",
    "results = pd.DataFrame(data=data)\n",
    "print(results)\n",
    "print()\n",
    "print('Параметры наилучшей модели случайного леса:')\n",
    "print(results[results['f1'] == results['f1'].max()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Обучение модели логистической регрессии на масштабированной выборке"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-метрика модели логистической регрессии на масштабированной выборке -  0.0\n",
      "AUC-ROC-метрика модели логистической регрессии на масштабированной выборке -  0.493\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "# создадим объект 'model' структуры данных LogisticRegression\n",
    "# зададим псевдослучайность random_state=12345\n",
    "model = LogisticRegression(random_state=12345,\n",
    "                           solver='liblinear')\n",
    "\n",
    "# обучим модель на обучающей выборке\n",
    "model.fit(features_train_scaled, target_train)\n",
    "\n",
    "# произведем предсказания на валидационной выборке\n",
    "predictions = model.predict(features_valid_scaled)\n",
    "\n",
    "# качество предсказаний на валидационной выборке\n",
    "# f1-метрика\n",
    "print('F1-метрика модели логистической регрессии на масштабированной выборке - ', np.round(f1_score(target_valid, predictions),3))\n",
    "\n",
    "# roc_auc_score\n",
    "# для расчета метрики area under ROC-curve необходимо вычислить вероятности класса \"1\" \n",
    "probabilities_valid = model.predict_proba(features_valid_scaled)\n",
    "probabilities_one_valid = probabilities_valid[:, 1]\n",
    "\n",
    "auc_roc = roc_auc_score(target_valid, probabilities_one_valid)\n",
    "print('AUC-ROC-метрика модели логистической регрессии на масштабированной выборке - ', np.round(auc_roc,3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Вывод"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Были обучены модели дерева решений, случайного леса, логистической регрессии с учетом дисбаланса классов `методом масштабирования признаков`;\n",
    "\n",
    "\n",
    "2. Рассчитаны метрики качества F1 и AUC-ROC для каждой модели:\n",
    "\n",
    "    2.3 F1-метрика с учетом дисбаланса классов для моделей:\n",
    "    * наилучшая модель дерева решений `глубиной 9` - `0.573`\n",
    "    * наилучшая модель случайного леса с количеством деревьев в ансамбле `35` и глубиной дерева `12` - `0.596`\n",
    "    * модель логистической регрессии на масштабированной выборке -  `не смогла посчитать`\n",
    "\n",
    "    2.4 AUC-ROC-метрика с учетом дисбаланса классов для моделей:\n",
    "    * наилучшая модель дерева решений `глубиной 9` - `0.782` \n",
    "    * наилучшая модель случайного леса с количеством деревьев в ансамбле `35` и глубиной дерева `12` - `0.848`\n",
    "    * модель логистической регрессии на масштабированной выборке -  `0.493`\n",
    "\n",
    "\n",
    "3. `Наилучшие результаты` с учетом дисбаланса классов `методом масштабирования признаков` и предельно большим значением F1-меры на валидационной выборке показала `модель случайного леса с количеством деревьев в ансамбле равным 35 и глубиной дерева 12`: \n",
    "    * F1 - `0.596`\n",
    "    * AUC-ROC - `0.848`    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Общий вывод по п.4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Для борьбы с дисбалансом классов были применены несколько методов: взвешивание классов, изменение порога логистической регрессии, увеличение и уменьшение выборки, масштабирование признаков;\n",
    "\n",
    "\n",
    "2. В рамках каждого метода обучены модели дерева решений, случайного леса, логистической регрессии с учетом дисбаланса классов и рассчитаны метрики качества F1 и AUC-ROC:\n",
    "\n",
    "    2.1 `Наилучшие результаты` с учетом дисбаланса классов `путем их взвешивания` и предельно большим значением F1-меры на валидационной выборке показала `модель случайного леса с количеством деревьев в ансамбле равным 44 и глубиной дерева 6`: \n",
    "    * F1 - `0.626`\n",
    "    * AUC-ROC - `0.851`\n",
    "    \n",
    "    2.2 `Наилучшие результаты` F1-меры при `изменении порога` для несбалансированных классов показала модель логистической регрессии с `порогом 0.15` и значением `F1-меры -  0.37`;\n",
    "    \n",
    "    2.3 `Наилучшие результаты` с учетом дисбаланса классов `методом upsampling` (увеличение объектов редкого класса) и предельно большим значением F1-меры на валидационной выборке показала `модель случайного леса с количеством деревьев в ансамбле равным 48 и глубиной дерева 6`: \n",
    "    * F1 - `0.626`\n",
    "    * AUC-ROC - `0.851`\n",
    "    \n",
    "    2.4 `Наилучшие результаты` с учетом дисбаланса классов `методом downsampling` (уменьшение объектов частого класса) и предельно большим значением F1-меры на валидационной выборке показала `модель случайного леса с количеством деревьев в ансамбле равным 50 и глубиной дерева 6`: \n",
    "    * F1 - `0.615`\n",
    "    * AUC-ROC - `0.847`\n",
    "    \n",
    "    2.5 `Наилучшие результаты` с учетом дисбаланса классов `методом масштабирования признаков` и предельно большим значением F1-меры на валидационной выборке показала `модель случайного леса с количеством деревьев в ансамбле равным 35 и глубиной дерева 12`: \n",
    "    * F1 - `0.596`\n",
    "    * AUC-ROC - `0.848`\n",
    "    \n",
    "    \n",
    "3. Таким образом можно сделать вывод, что для борьбы с дисбалансом классов на валидационной выборке `наилучшие результаты` показали методы `взвешивания классов` и `upsampling`. Они дали практически идентичные результаты F1 и AUC-ROC-метрик. При этом стоит отметить, что в данном случае у метода `взвешивания классов` есть ряд важных преимуществ, а именно:\n",
    "    * простота использования;\n",
    "    * более быстрое обучение: требования по количеству деревьев в ансамбле ниже, чем при методе upsampling (44 против 46 в методе upsampling)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Тестирование модели"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проведем финальное тестирование наилучшей модели случайного леса, указанной в п.4.6:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-метрика с взвешиванием классов модели случайного леса (ансамбль 44 деревьев с глубиной дерева 6) -  0.605\n",
      "AUC-ROC-метрика с взвешиванием классов модели случайного леса (ансамбль 44 деревьев с глубиной дерева 6) -  0.849\n"
     ]
    }
   ],
   "source": [
    "# создадим объект 'model' структуры данных RandomForestClassifier\n",
    "# зададим псевдослучайность random_state=12345, максимальную глубину дерева - 6\n",
    "# учитывая баланс классов class_weight='balanced', кол-во деревьев в ансамбле n_estimators=44\n",
    "model = RandomForestClassifier(random_state=12345,\n",
    "                               class_weight='balanced',\n",
    "                               n_estimators=44,\n",
    "                               max_depth=6)\n",
    "\n",
    "# обучим модель на обучающей выборке\n",
    "model.fit(features_train, target_train)\n",
    "\n",
    "# произведем предсказания на тестовой выборке\n",
    "predictions = model.predict(features_test)\n",
    "\n",
    "# качество предсказаний на тестовой выборке\n",
    "# f1-метрика\n",
    "print('F1-метрика с взвешиванием классов модели случайного леса (ансамбль 44 деревьев с глубиной дерева 6) - ', np.round(f1_score(target_test, predictions),3))\n",
    "\n",
    "# roc_auc_score\n",
    "# для расчета метрики area under ROC-curve необходимо вычислить вероятности класса \"1\" \n",
    "probabilities_test = model.predict_proba(features_test)\n",
    "probabilities_one_test = probabilities_test[:, 1]\n",
    "\n",
    "auc_roc = roc_auc_score(target_test, probabilities_one_test)\n",
    "print('AUC-ROC-метрика с взвешиванием классов модели случайного леса (ансамбль 44 деревьев с глубиной дерева 6) - ', np.round(auc_roc,3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Дополнительно визуализируем график ROC-кривой, на которой отобразим ROC-кривую полученной модели случайного леса и случайной модели:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# с помощью функции 'roc_curve' получим значения false positive rate, true positive rate\n",
    "# полученной модели случайного леса\n",
    "fpr, tpr, thresholds = roc_curve(target_test, probabilities_one_test)\n",
    "\n",
    "\n",
    "plt.figure(figsize=(6,6))\n",
    "plt.plot(fpr, tpr, linestyle='-.')\n",
    "\n",
    "# ROC-кривая случайной модели (выглядит как прямая)\n",
    "plt.plot([0, 1], [0, 1], linestyle='dotted')\n",
    "\n",
    "# установим границы осей от 0 до 1\n",
    "plt.xlim([0.0,1.0])\n",
    "plt.ylim([0.0,1.0])\n",
    "\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.xlabel('False Positive Rate')\n",
    "\n",
    "plt.title('ROC-кривая')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Итоги исследования"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Отток клиентов` - исследовательский проект, целью которого являлось разработать прогнозную модель ухода клиента из банка в ближайшее время, а именно:\n",
    "* Построить модель с предельно большим значением *F1*-меры. Чтобы сдать проект успешно, нужно довести метрику до 0.59. Проверьте *F1*-меру на тестовой выборке самостоятельно.\n",
    "* Дополнительно измерить *AUC-ROC*, сравнить её значение с *F1*-мерой.\n",
    "\n",
    "В качестве исходной информации были предоставлены исторические данные о поведении клиентов и расторжении договоров с банком.\n",
    "\n",
    "Для достижения указанной цели были поставлены и решены следующие задачи:\n",
    "1. На первом этапе были загружены и подготовлены исходые данные:\n",
    "\n",
    "    * столбец `RowNumber` удален;\n",
    "    * заголовки столбцов приведены к \"змеиному регистру\";\n",
    "    * пропуски в столбце `Tenure` заменены на `медианное значение столбца`;\n",
    "    * данные столбцов `Gender` и `Geography` закодированы с помощью техники OHE (прямого кодирования)\n",
    "    \n",
    "\n",
    "2. На этапе исследования задачи:\n",
    "\n",
    "    * был выявлен значительный дисбаланс классов в сторону `0` значений (около 80%);\n",
    "    * обучены модели дерева решений, случайного леса, логистической регрессии, рассчитаны метрики качества F1 и AUC-ROC для каждой модели без учета дисбаланса классов;\n",
    "\n",
    "\n",
    "3. На этапе борьбы с дисбалансом классов был применен ряд методов: взвешивание классов, изменение порога логистической регрессии, увеличение и уменьшение выборки, масштабирование признаков. Получены следующие результаты:\n",
    "\n",
    "    3.1 `Наилучшие результаты` с учетом дисбаланса классов `путем их взвешивания` и предельно большим значением F1-меры на валидационной выборке показала `модель случайного леса с количеством деревьев в ансамбле равным 44 и глубиной дерева 6`: \n",
    "    * F1 - `0.626`\n",
    "    * AUC-ROC - `0.851`\n",
    "    \n",
    "    3.2 `Наилучшие результаты` F1-меры при `изменении порога` для несбалансированных классов показала модель логистической регрессии с `порогом 0.15` и значением `F1-меры -  0.37`;\n",
    "    \n",
    "    3.3 `Наилучшие результаты` с учетом дисбаланса классов `методом upsampling` (увеличение объектов редкого класса) и предельно большим значением F1-меры на валидационной выборке показала `модель случайного леса с количеством деревьев в ансамбле равным 48 и глубиной дерева 6`: \n",
    "    * F1 - `0.626`\n",
    "    * AUC-ROC - `0.851`\n",
    "    \n",
    "    3.4 `Наилучшие результаты` с учетом дисбаланса классов `методом downsampling` (уменьшение объектов частого класса) и предельно большим значением F1-меры на валидационной выборке показала `модель случайного леса с количеством деревьев в ансамбле равным 50 и глубиной дерева 6`: \n",
    "    * F1 - `0.615`\n",
    "    * AUC-ROC - `0.847`\n",
    "    \n",
    "    3.5 `Наилучшие результаты` с учетом дисбаланса классов `методом масштабирования признаков` и предельно большим значением F1-меры на валидационной выборке показала `модель случайного леса с количеством деревьев в ансамбле равным 35 и глубиной дерева 12`: \n",
    "    * F1 - `0.596`\n",
    "    * AUC-ROC - `0.848`\n",
    "    \n",
    "    \n",
    "4. Сделан вывод, что для борьбы с дисбалансом классов из представленных методов на валидационной выборке `наилучшие результаты` показали методы `взвешивания классов` и `upsampling`. Они дали практически идентичные результаты F1 и AUC-ROC-метрик. Однако, в нашем случае у метода `взвешивания классов` оказался ряд важных преимуществ, а именно:\n",
    "    * простота использования;\n",
    "    * более быстрое обучение: требования по количеству деревьев в ансамбле ниже, чем при методе upsampling (44 против 46 в методе upsampling)\n",
    "    \n",
    "\n",
    "5. В конце выполнена финальная проверка `наилучшей модели случайного леса` с `взвешиванием классов` на тестовой выборке, метрики качества которой показали следующие результаты:\n",
    "    * `F1-метрика` с `взвешиванием классов` модели случайного леса (ансамбль 44 деревьев с глубиной дерева 6) - `0.605`\n",
    "    * `AUC-ROC-метрика` с `взвешиванием классов` модели случайного леса (ансамбль 44 деревьев с глубиной дерева 6) -  `0.849`."
   ]
  }
 ],
 "metadata": {
  "ExecuteTimeLog": [
   {
    "duration": 4,
    "start_time": "2022-03-02T13:08:04.500Z"
   },
   {
    "duration": 1131,
    "start_time": "2022-03-04T06:21:03.689Z"
   },
   {
    "duration": 96,
    "start_time": "2022-03-04T06:22:09.454Z"
   },
   {
    "duration": 89,
    "start_time": "2022-03-04T06:23:01.242Z"
   },
   {
    "duration": 89,
    "start_time": "2022-03-04T07:18:38.954Z"
   },
   {
    "duration": 86,
    "start_time": "2022-03-04T07:18:46.927Z"
   },
   {
    "duration": 88,
    "start_time": "2022-03-04T07:19:22.553Z"
   },
   {
    "duration": 85,
    "start_time": "2022-03-04T07:19:29.893Z"
   },
   {
    "duration": 100,
    "start_time": "2022-03-04T07:19:56.481Z"
   },
   {
    "duration": 100,
    "start_time": "2022-03-04T07:20:09.233Z"
   },
   {
    "duration": 1543,
    "start_time": "2022-03-04T07:20:34.335Z"
   },
   {
    "duration": 84,
    "start_time": "2022-03-04T07:20:43.570Z"
   },
   {
    "duration": 89,
    "start_time": "2022-03-04T07:20:48.433Z"
   },
   {
    "duration": 86,
    "start_time": "2022-03-04T07:20:55.181Z"
   },
   {
    "duration": 12,
    "start_time": "2022-03-04T07:21:02.434Z"
   },
   {
    "duration": 5,
    "start_time": "2022-03-04T07:29:23.235Z"
   },
   {
    "duration": 319,
    "start_time": "2022-03-04T07:29:26.654Z"
   },
   {
    "duration": 244,
    "start_time": "2022-03-04T07:29:41.553Z"
   },
   {
    "duration": 229,
    "start_time": "2022-03-04T07:30:34.107Z"
   },
   {
    "duration": 221,
    "start_time": "2022-03-04T07:30:45.753Z"
   },
   {
    "duration": 220,
    "start_time": "2022-03-04T07:31:27.773Z"
   },
   {
    "duration": 1118,
    "start_time": "2022-03-04T07:32:18.483Z"
   },
   {
    "duration": 103,
    "start_time": "2022-03-04T07:32:19.603Z"
   },
   {
    "duration": 12,
    "start_time": "2022-03-04T07:32:19.709Z"
   },
   {
    "duration": 26,
    "start_time": "2022-03-04T07:32:19.723Z"
   },
   {
    "duration": 337,
    "start_time": "2022-03-04T07:33:25.422Z"
   },
   {
    "duration": 212,
    "start_time": "2022-03-04T07:33:31.682Z"
   },
   {
    "duration": 1024,
    "start_time": "2022-03-04T07:33:37.602Z"
   },
   {
    "duration": 100,
    "start_time": "2022-03-04T07:33:38.628Z"
   },
   {
    "duration": 12,
    "start_time": "2022-03-04T07:33:38.730Z"
   },
   {
    "duration": 7,
    "start_time": "2022-03-04T07:33:38.743Z"
   },
   {
    "duration": 335,
    "start_time": "2022-03-04T07:33:56.942Z"
   },
   {
    "duration": 1159,
    "start_time": "2022-03-04T07:34:04.874Z"
   },
   {
    "duration": 99,
    "start_time": "2022-03-04T07:34:06.035Z"
   },
   {
    "duration": 11,
    "start_time": "2022-03-04T07:34:06.136Z"
   },
   {
    "duration": 9,
    "start_time": "2022-03-04T07:34:06.149Z"
   },
   {
    "duration": 21,
    "start_time": "2022-03-04T07:34:21.662Z"
   },
   {
    "duration": 6,
    "start_time": "2022-03-04T07:35:00.442Z"
   },
   {
    "duration": 21,
    "start_time": "2022-03-04T07:35:19.465Z"
   },
   {
    "duration": 7,
    "start_time": "2022-03-04T07:36:19.621Z"
   },
   {
    "duration": 22,
    "start_time": "2022-03-04T07:37:05.582Z"
   },
   {
    "duration": 7,
    "start_time": "2022-03-04T07:37:24.923Z"
   },
   {
    "duration": 10,
    "start_time": "2022-03-04T08:27:42.322Z"
   },
   {
    "duration": 12,
    "start_time": "2022-03-04T08:28:05.482Z"
   },
   {
    "duration": 10,
    "start_time": "2022-03-04T08:28:36.904Z"
   },
   {
    "duration": 8,
    "start_time": "2022-03-04T08:29:04.242Z"
   },
   {
    "duration": 21,
    "start_time": "2022-03-04T08:29:50.522Z"
   },
   {
    "duration": 1649,
    "start_time": "2022-03-04T08:34:36.821Z"
   },
   {
    "duration": 22,
    "start_time": "2022-03-04T08:34:50.561Z"
   },
   {
    "duration": 23,
    "start_time": "2022-03-04T08:35:09.202Z"
   },
   {
    "duration": 11,
    "start_time": "2022-03-04T08:46:54.282Z"
   },
   {
    "duration": 21,
    "start_time": "2022-03-04T08:54:25.982Z"
   },
   {
    "duration": 78,
    "start_time": "2022-03-04T08:59:58.310Z"
   },
   {
    "duration": 81,
    "start_time": "2022-03-04T09:00:09.970Z"
   },
   {
    "duration": 83,
    "start_time": "2022-03-04T09:00:25.124Z"
   },
   {
    "duration": 13,
    "start_time": "2022-03-04T09:01:06.522Z"
   },
   {
    "duration": 14,
    "start_time": "2022-03-04T09:01:34.702Z"
   },
   {
    "duration": 1171,
    "start_time": "2022-03-04T09:56:49.667Z"
   },
   {
    "duration": 105,
    "start_time": "2022-03-04T09:56:50.840Z"
   },
   {
    "duration": 12,
    "start_time": "2022-03-04T09:56:50.947Z"
   },
   {
    "duration": 19,
    "start_time": "2022-03-04T09:56:50.961Z"
   },
   {
    "duration": 1073,
    "start_time": "2022-03-06T10:08:04.565Z"
   },
   {
    "duration": 80,
    "start_time": "2022-03-06T10:08:05.640Z"
   },
   {
    "duration": 10,
    "start_time": "2022-03-06T10:08:05.722Z"
   },
   {
    "duration": 13,
    "start_time": "2022-03-06T10:08:05.734Z"
   },
   {
    "duration": 36,
    "start_time": "2022-03-06T10:08:05.749Z"
   },
   {
    "duration": 15,
    "start_time": "2022-03-06T10:08:05.787Z"
   },
   {
    "duration": 8,
    "start_time": "2022-03-06T10:08:05.803Z"
   },
   {
    "duration": 9,
    "start_time": "2022-03-06T10:08:06.165Z"
   },
   {
    "duration": 12,
    "start_time": "2022-03-06T10:08:06.176Z"
   },
   {
    "duration": 43,
    "start_time": "2022-03-06T10:08:06.190Z"
   },
   {
    "duration": 96,
    "start_time": "2022-03-06T10:08:06.581Z"
   },
   {
    "duration": 85,
    "start_time": "2022-03-06T10:08:06.679Z"
   },
   {
    "duration": 132,
    "start_time": "2022-03-06T10:08:06.766Z"
   },
   {
    "duration": 1615,
    "start_time": "2022-03-06T10:08:06.900Z"
   },
   {
    "duration": 98,
    "start_time": "2022-03-06T10:08:08.517Z"
   },
   {
    "duration": 106726,
    "start_time": "2022-03-06T10:08:08.617Z"
   },
   {
    "duration": 123,
    "start_time": "2022-03-06T10:09:55.345Z"
   },
   {
    "duration": 304,
    "start_time": "2022-03-06T10:09:55.471Z"
   },
   {
    "duration": 4,
    "start_time": "2022-03-06T10:10:59.421Z"
   },
   {
    "duration": 327,
    "start_time": "2022-03-07T13:10:55.664Z"
   },
   {
    "duration": 1368,
    "start_time": "2022-03-07T13:11:06.606Z"
   },
   {
    "duration": 136,
    "start_time": "2022-03-07T13:11:07.977Z"
   },
   {
    "duration": 14,
    "start_time": "2022-03-07T13:11:08.116Z"
   },
   {
    "duration": 22,
    "start_time": "2022-03-07T13:11:08.133Z"
   },
   {
    "duration": 34,
    "start_time": "2022-03-07T13:11:08.158Z"
   },
   {
    "duration": 27,
    "start_time": "2022-03-07T13:11:08.195Z"
   },
   {
    "duration": 12,
    "start_time": "2022-03-07T13:11:08.252Z"
   },
   {
    "duration": 9,
    "start_time": "2022-03-07T13:11:08.268Z"
   },
   {
    "duration": 17,
    "start_time": "2022-03-07T13:11:08.279Z"
   },
   {
    "duration": 97,
    "start_time": "2022-03-07T13:11:08.299Z"
   },
   {
    "duration": 145,
    "start_time": "2022-03-07T13:11:08.399Z"
   },
   {
    "duration": 206,
    "start_time": "2022-03-07T13:11:08.546Z"
   },
   {
    "duration": 56,
    "start_time": "2022-03-07T13:11:08.755Z"
   },
   {
    "duration": 2199,
    "start_time": "2022-03-07T13:11:08.814Z"
   },
   {
    "duration": 137,
    "start_time": "2022-03-07T13:11:11.016Z"
   },
   {
    "duration": 1316,
    "start_time": "2022-03-07T13:11:52.751Z"
   },
   {
    "duration": 132,
    "start_time": "2022-03-07T13:11:54.069Z"
   },
   {
    "duration": 15,
    "start_time": "2022-03-07T13:11:54.204Z"
   },
   {
    "duration": 5,
    "start_time": "2022-03-07T13:11:54.221Z"
   },
   {
    "duration": 51,
    "start_time": "2022-03-07T13:11:54.229Z"
   },
   {
    "duration": 24,
    "start_time": "2022-03-07T13:11:54.282Z"
   },
   {
    "duration": 11,
    "start_time": "2022-03-07T13:11:54.309Z"
   },
   {
    "duration": 8,
    "start_time": "2022-03-07T13:11:54.352Z"
   },
   {
    "duration": 15,
    "start_time": "2022-03-07T13:11:54.363Z"
   },
   {
    "duration": 92,
    "start_time": "2022-03-07T13:11:54.381Z"
   },
   {
    "duration": 199,
    "start_time": "2022-03-07T13:11:54.476Z"
   },
   {
    "duration": 84,
    "start_time": "2022-03-07T13:11:54.678Z"
   },
   {
    "duration": 146,
    "start_time": "2022-03-07T13:11:54.857Z"
   },
   {
    "duration": 2246,
    "start_time": "2022-03-07T13:11:55.006Z"
   },
   {
    "duration": 142,
    "start_time": "2022-03-07T13:11:57.254Z"
   },
   {
    "duration": 141659,
    "start_time": "2022-03-07T13:11:57.399Z"
   },
   {
    "duration": 290,
    "start_time": "2022-03-07T13:14:19.061Z"
   },
   {
    "duration": 318,
    "start_time": "2022-03-07T13:14:19.354Z"
   },
   {
    "duration": 475,
    "start_time": "2022-03-07T13:14:19.675Z"
   },
   {
    "duration": 246,
    "start_time": "2022-03-07T13:18:34.748Z"
   },
   {
    "duration": 334,
    "start_time": "2022-03-07T13:21:54.348Z"
   },
   {
    "duration": 317,
    "start_time": "2022-03-07T13:22:13.396Z"
   },
   {
    "duration": 220,
    "start_time": "2022-03-07T13:25:40.060Z"
   },
   {
    "duration": 259,
    "start_time": "2022-03-07T13:26:39.019Z"
   },
   {
    "duration": 241,
    "start_time": "2022-03-07T13:44:00.138Z"
   },
   {
    "duration": 5,
    "start_time": "2022-03-07T13:53:59.412Z"
   },
   {
    "duration": 4,
    "start_time": "2022-03-07T13:54:43.194Z"
   },
   {
    "duration": 10,
    "start_time": "2022-03-07T14:06:10.471Z"
   },
   {
    "duration": 580,
    "start_time": "2022-03-07T14:22:26.298Z"
   },
   {
    "duration": 5,
    "start_time": "2022-03-07T14:22:58.133Z"
   },
   {
    "duration": 5,
    "start_time": "2022-03-07T14:23:20.581Z"
   },
   {
    "duration": 4,
    "start_time": "2022-03-07T14:23:37.416Z"
   },
   {
    "duration": 5,
    "start_time": "2022-03-07T14:23:42.776Z"
   },
   {
    "duration": 4,
    "start_time": "2022-03-07T14:23:45.653Z"
   },
   {
    "duration": 5,
    "start_time": "2022-03-07T14:23:49.582Z"
   },
   {
    "duration": 463,
    "start_time": "2022-03-07T14:24:19.134Z"
   },
   {
    "duration": 282,
    "start_time": "2022-03-07T14:25:15.533Z"
   },
   {
    "duration": 4,
    "start_time": "2022-03-07T14:25:33.335Z"
   },
   {
    "duration": 4,
    "start_time": "2022-03-07T14:28:47.661Z"
   },
   {
    "duration": 5,
    "start_time": "2022-03-07T14:28:59.532Z"
   },
   {
    "duration": 21,
    "start_time": "2022-03-07T14:29:28.889Z"
   },
   {
    "duration": 2808,
    "start_time": "2022-03-07T14:31:57.294Z"
   },
   {
    "duration": 22,
    "start_time": "2022-03-07T14:40:50.972Z"
   },
   {
    "duration": 1337,
    "start_time": "2022-03-07T14:41:16.692Z"
   },
   {
    "duration": 190805,
    "start_time": "2022-03-07T14:41:44.331Z"
   },
   {
    "duration": 108,
    "start_time": "2022-03-07T14:49:14.659Z"
   },
   {
    "duration": 19,
    "start_time": "2022-03-07T15:05:03.015Z"
   },
   {
    "duration": 267,
    "start_time": "2022-03-07T15:06:19.412Z"
   },
   {
    "duration": 21,
    "start_time": "2022-03-07T15:07:06.871Z"
   },
   {
    "duration": 310,
    "start_time": "2022-03-07T15:07:09.019Z"
   },
   {
    "duration": 167,
    "start_time": "2022-03-07T15:08:55.908Z"
   },
   {
    "duration": 203,
    "start_time": "2022-03-07T15:09:36.452Z"
   },
   {
    "duration": 147,
    "start_time": "2022-03-07T15:09:55.611Z"
   },
   {
    "duration": 167,
    "start_time": "2022-03-07T15:10:01.411Z"
   },
   {
    "duration": 144,
    "start_time": "2022-03-07T15:10:18.686Z"
   },
   {
    "duration": 274,
    "start_time": "2022-03-07T15:10:46.419Z"
   },
   {
    "duration": 172,
    "start_time": "2022-03-07T15:11:02.612Z"
   },
   {
    "duration": 22,
    "start_time": "2022-03-07T15:13:04.092Z"
   },
   {
    "duration": 20,
    "start_time": "2022-03-07T15:13:10.299Z"
   },
   {
    "duration": 21,
    "start_time": "2022-03-07T15:13:27.731Z"
   },
   {
    "duration": 20,
    "start_time": "2022-03-07T15:13:44.423Z"
   },
   {
    "duration": 501,
    "start_time": "2022-03-07T15:13:47.355Z"
   },
   {
    "duration": 210,
    "start_time": "2022-03-08T08:42:35.132Z"
   },
   {
    "duration": 1000,
    "start_time": "2022-03-08T08:42:43.192Z"
   },
   {
    "duration": 211,
    "start_time": "2022-03-08T08:42:47.261Z"
   },
   {
    "duration": 177,
    "start_time": "2022-03-08T08:42:54.078Z"
   },
   {
    "duration": 987,
    "start_time": "2022-03-08T08:43:08.617Z"
   },
   {
    "duration": 90,
    "start_time": "2022-03-08T08:43:09.606Z"
   },
   {
    "duration": 10,
    "start_time": "2022-03-08T08:43:09.699Z"
   },
   {
    "duration": 4,
    "start_time": "2022-03-08T08:43:09.711Z"
   },
   {
    "duration": 25,
    "start_time": "2022-03-08T08:43:09.717Z"
   },
   {
    "duration": 34,
    "start_time": "2022-03-08T08:43:09.744Z"
   },
   {
    "duration": 9,
    "start_time": "2022-03-08T08:43:09.779Z"
   },
   {
    "duration": 5,
    "start_time": "2022-03-08T08:43:09.790Z"
   },
   {
    "duration": 14,
    "start_time": "2022-03-08T08:43:09.798Z"
   },
   {
    "duration": 76,
    "start_time": "2022-03-08T08:43:09.814Z"
   },
   {
    "duration": 91,
    "start_time": "2022-03-08T08:43:09.892Z"
   },
   {
    "duration": 80,
    "start_time": "2022-03-08T08:43:09.984Z"
   },
   {
    "duration": 133,
    "start_time": "2022-03-08T08:43:10.067Z"
   },
   {
    "duration": 1576,
    "start_time": "2022-03-08T08:43:10.202Z"
   },
   {
    "duration": 93,
    "start_time": "2022-03-08T08:43:11.780Z"
   },
   {
    "duration": 92583,
    "start_time": "2022-03-08T08:43:11.875Z"
   },
   {
    "duration": 100,
    "start_time": "2022-03-08T08:44:44.463Z"
   },
   {
    "duration": 307,
    "start_time": "2022-03-08T08:44:44.565Z"
   },
   {
    "duration": 14,
    "start_time": "2022-03-08T08:44:44.874Z"
   },
   {
    "duration": 1000,
    "start_time": "2022-03-08T08:44:44.890Z"
   },
   {
    "duration": 127374,
    "start_time": "2022-03-08T08:44:45.892Z"
   },
   {
    "duration": 96,
    "start_time": "2022-03-08T08:46:53.268Z"
   },
   {
    "duration": 104,
    "start_time": "2022-03-08T08:46:53.366Z"
   },
   {
    "duration": 363,
    "start_time": "2022-03-08T08:46:53.471Z"
   },
   {
    "duration": 54705,
    "start_time": "2022-03-08T08:46:53.835Z"
   },
   {
    "duration": 221,
    "start_time": "2022-03-08T08:47:48.542Z"
   },
   {
    "duration": 21,
    "start_time": "2022-03-08T08:52:23.782Z"
   },
   {
    "duration": 100,
    "start_time": "2022-03-08T08:53:47.368Z"
   },
   {
    "duration": 18,
    "start_time": "2022-03-08T08:54:14.847Z"
   },
   {
    "duration": 3,
    "start_time": "2022-03-08T09:01:00.344Z"
   },
   {
    "duration": 21,
    "start_time": "2022-03-08T09:50:04.663Z"
   },
   {
    "duration": 19,
    "start_time": "2022-03-08T09:51:09.702Z"
   },
   {
    "duration": 16,
    "start_time": "2022-03-08T09:58:35.982Z"
   },
   {
    "duration": 16,
    "start_time": "2022-03-08T09:59:06.310Z"
   },
   {
    "duration": 785,
    "start_time": "2022-03-08T10:03:12.463Z"
   },
   {
    "duration": 93484,
    "start_time": "2022-03-08T10:06:05.152Z"
   },
   {
    "duration": 141,
    "start_time": "2022-03-08T10:10:19.823Z"
   },
   {
    "duration": 21,
    "start_time": "2022-03-08T10:13:41.302Z"
   },
   {
    "duration": 3,
    "start_time": "2022-03-08T11:10:07.942Z"
   },
   {
    "duration": 202,
    "start_time": "2022-03-08T11:11:50.591Z"
   },
   {
    "duration": 325,
    "start_time": "2022-03-08T11:12:39.231Z"
   },
   {
    "duration": 73,
    "start_time": "2022-03-08T11:12:52.342Z"
   },
   {
    "duration": 172,
    "start_time": "2022-03-08T11:17:53.704Z"
   },
   {
    "duration": 209,
    "start_time": "2022-03-08T11:18:00.429Z"
   },
   {
    "duration": 161,
    "start_time": "2022-03-08T11:18:03.302Z"
   },
   {
    "duration": 13,
    "start_time": "2022-03-08T11:18:37.502Z"
   },
   {
    "duration": 200,
    "start_time": "2022-03-08T11:18:43.503Z"
   },
   {
    "duration": 165,
    "start_time": "2022-03-08T11:18:54.392Z"
   },
   {
    "duration": 354,
    "start_time": "2022-03-08T11:19:04.020Z"
   },
   {
    "duration": 377,
    "start_time": "2022-03-08T11:19:10.990Z"
   },
   {
    "duration": 173,
    "start_time": "2022-03-08T11:19:26.342Z"
   },
   {
    "duration": 169,
    "start_time": "2022-03-08T11:19:42.103Z"
   },
   {
    "duration": 405,
    "start_time": "2022-03-08T11:19:48.822Z"
   },
   {
    "duration": 166,
    "start_time": "2022-03-08T11:20:02.543Z"
   },
   {
    "duration": 1063,
    "start_time": "2022-03-08T11:41:41.789Z"
   },
   {
    "duration": 85,
    "start_time": "2022-03-08T11:41:42.854Z"
   },
   {
    "duration": 10,
    "start_time": "2022-03-08T11:41:42.941Z"
   },
   {
    "duration": 12,
    "start_time": "2022-03-08T11:41:42.953Z"
   },
   {
    "duration": 25,
    "start_time": "2022-03-08T11:41:42.966Z"
   },
   {
    "duration": 16,
    "start_time": "2022-03-08T11:41:42.992Z"
   },
   {
    "duration": 7,
    "start_time": "2022-03-08T11:41:43.009Z"
   },
   {
    "duration": 5,
    "start_time": "2022-03-08T11:41:43.018Z"
   },
   {
    "duration": 38,
    "start_time": "2022-03-08T11:41:43.025Z"
   },
   {
    "duration": 45,
    "start_time": "2022-03-08T11:41:43.065Z"
   },
   {
    "duration": 104,
    "start_time": "2022-03-08T11:41:43.112Z"
   },
   {
    "duration": 54,
    "start_time": "2022-03-08T11:41:43.218Z"
   },
   {
    "duration": 133,
    "start_time": "2022-03-08T11:41:43.365Z"
   },
   {
    "duration": 1608,
    "start_time": "2022-03-08T11:41:43.500Z"
   },
   {
    "duration": 96,
    "start_time": "2022-03-08T11:41:45.109Z"
   },
   {
    "duration": 94212,
    "start_time": "2022-03-08T11:41:45.206Z"
   },
   {
    "duration": 243,
    "start_time": "2022-03-08T11:43:19.420Z"
   },
   {
    "duration": 312,
    "start_time": "2022-03-08T11:43:19.665Z"
   },
   {
    "duration": 15,
    "start_time": "2022-03-08T11:43:19.978Z"
   },
   {
    "duration": 953,
    "start_time": "2022-03-08T11:43:19.995Z"
   },
   {
    "duration": 129242,
    "start_time": "2022-03-08T11:43:20.950Z"
   },
   {
    "duration": 74,
    "start_time": "2022-03-08T11:45:30.194Z"
   },
   {
    "duration": 197,
    "start_time": "2022-03-08T11:45:30.271Z"
   },
   {
    "duration": 378,
    "start_time": "2022-03-08T11:45:30.470Z"
   },
   {
    "duration": 55882,
    "start_time": "2022-03-08T11:45:30.850Z"
   },
   {
    "duration": 132,
    "start_time": "2022-03-08T11:46:26.734Z"
   },
   {
    "duration": 111,
    "start_time": "2022-03-08T11:46:26.870Z"
   },
   {
    "duration": 768,
    "start_time": "2022-03-08T11:46:26.983Z"
   },
   {
    "duration": 94286,
    "start_time": "2022-03-08T11:46:27.753Z"
   },
   {
    "duration": 123,
    "start_time": "2022-03-08T11:48:02.041Z"
   },
   {
    "duration": 308,
    "start_time": "2022-03-08T11:48:02.167Z"
   },
   {
    "duration": 179,
    "start_time": "2022-03-08T11:48:02.476Z"
   },
   {
    "duration": 208,
    "start_time": "2022-03-08T11:50:14.260Z"
   },
   {
    "duration": 13,
    "start_time": "2022-03-08T11:50:35.060Z"
   },
   {
    "duration": 237,
    "start_time": "2022-03-08T11:50:41.860Z"
   },
   {
    "duration": 52,
    "start_time": "2022-03-08T11:51:05.020Z"
   },
   {
    "duration": 209,
    "start_time": "2022-03-08T11:51:10.180Z"
   },
   {
    "duration": 19,
    "start_time": "2022-03-08T11:52:31.020Z"
   },
   {
    "duration": 773,
    "start_time": "2022-03-08T11:52:36.668Z"
   },
   {
    "duration": 210,
    "start_time": "2022-03-08T11:53:02.139Z"
   },
   {
    "duration": 17,
    "start_time": "2022-03-08T11:53:18.142Z"
   },
   {
    "duration": 224,
    "start_time": "2022-03-08T11:53:23.700Z"
   },
   {
    "duration": 14,
    "start_time": "2022-03-08T11:53:33.140Z"
   },
   {
    "duration": 235,
    "start_time": "2022-03-08T11:53:38.860Z"
   },
   {
    "duration": 20,
    "start_time": "2022-03-08T11:54:09.699Z"
   },
   {
    "duration": 771,
    "start_time": "2022-03-08T11:54:16.820Z"
   },
   {
    "duration": 237,
    "start_time": "2022-03-08T11:54:26.820Z"
   },
   {
    "duration": 20,
    "start_time": "2022-03-08T11:55:20.339Z"
   },
   {
    "duration": 756,
    "start_time": "2022-03-08T11:55:22.822Z"
   },
   {
    "duration": 217,
    "start_time": "2022-03-08T11:55:30.539Z"
   },
   {
    "duration": 167,
    "start_time": "2022-03-08T11:55:43.787Z"
   }
  ],
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Содержание",
   "title_sidebar": "Содержание",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "255.594px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
